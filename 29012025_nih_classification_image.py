# -*- coding: utf-8 -*-
"""29012025 nih CLASSIFICATION IMAGE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1472MOHF0FTsdv8yjdsk0zQ8OroGNtKpT
"""

import random
import os
import cv2
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from skimage import exposure
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest
from google.colab import drive
from deap import base, creator, tools, algorithms


# Mount Google Drive
drive.mount('/content/drive')

# Paths
image_folder = '/content/drive/My Drive/IMAGE CLASSIFICATION PNEUMONIA/'
csv_file_path = '/content/drive/My Drive/IMAGE CLASSIFICATION PNEUMONIA/Images Label.csv'


# Load labels from CSV
labels_df = pd.read_csv(csv_file_path)
labels = labels_df['Label'].values  # Ensure this column exists in your dataset

# Load and preprocess images
def preprocess_image(image_path, target_size=(224, 224)):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Convert to grayscale
    if img is None:
        return None

    img = cv2.resize(img, target_size)

    # Apply Histogram Equalisation
    img = exposure.equalize_hist(img) * 255

    return img.astype(np.uint8)

# Feature Extraction using Custom GLCM
import itertools

def compute_glcm(image, distances=[1], angles=[0]):
    levels = 256
    glcm = np.zeros((levels, levels), dtype=np.float64)
    h, w = image.shape

    for d, theta in itertools.product(distances, angles):
        dx = int(d * np.cos(theta))
        dy = int(d * np.sin(theta))

        for i in range(h - dy):
            for j in range(w - dx):
                row = image[i, j]
                col = image[i + dy, j + dx]
                glcm[row, col] += 1
                glcm[col, row] += 1  # Symmetric matrix

    return glcm / glcm.sum()

def compute_glcm_features(image):
    glcm = compute_glcm(image)
    contrast = np.sum((np.arange(256)[:, None] - np.arange(256)) ** 2 * glcm)
    correlation = np.sum(np.outer(np.arange(256), np.arange(256)) * glcm)
    energy = np.sum(glcm ** 2)
    homogeneity = np.sum(glcm / (1 + np.abs(np.arange(256)[:, None] - np.arange(256))))
    return [contrast, correlation, energy, homogeneity]

def extract_features(images):
    return np.array([compute_glcm_features(img) for img in images])

# Genetic Algorithm for Feature Selection
def genetic_feature_selection(features, labels, num_features=10):
    creator.create("FitnessMax", base.Fitness, weights=(1.0,))
    creator.create("Individual", list, fitness=creator.FitnessMax)
    toolbox = base.Toolbox()
    toolbox.register("attr_bool", random.randint, 0, 1)
    toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=features.shape[1])
    toolbox.register("population", tools.initRepeat, list, toolbox.individual)

    def evaluate(individual):
        selected_features = np.where(individual)[0]
        if len(selected_features) == 0:
            return (0,)
        X_selected = features[:, selected_features]
        return (np.mean(X_selected),)

    toolbox.register("mate", tools.cxTwoPoint)
    toolbox.register("mutate", tools.mutFlipBit, indpb=0.05)
    toolbox.register("select", tools.selTournament, tournsize=3)
    toolbox.register("evaluate", evaluate)

    pop = toolbox.population(n=20)
    algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=10, verbose=False)
    best_individual = tools.selBest(pop, 1)[0]
    selected_features = np.where(best_individual)[0]
    return features[:, selected_features]

# Define U-Net Model with Recurrent Residual CNN
def build_unet(input_shape):
    inputs = tf.keras.Input(shape=input_shape)

    def conv_block(x, filters):
        res = x
        for _ in range(3):
            x = tf.keras.layers.Conv2D(filters, (3, 3), activation='relu', padding='same')(x)
        x = tf.keras.layers.Add()([x, res])
        return x

    filters = [64, 128, 256, 512]
    enc_layers = []
    x = inputs
    for f in filters:
        x = conv_block(x, f)
        enc_layers.append(x)
        x = tf.keras.layers.MaxPooling2D((2, 2))(x)

    for i in range(4):
        x = tf.keras.layers.UpSampling2D((2, 2))(x)
        x = tf.keras.layers.Concatenate()([x, enc_layers[-(i+1)]])
        x = conv_block(x, filters[-(i+1)])

    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(x)

    model = tf.keras.Model(inputs, outputs)
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Apply Cross-validation
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
print(f"Checking directory: {image_folder}")
if not os.path.exists(image_folder):
    raise ValueError(f"Image folder does not exist: {image_folder}")

print("Files in directory:", os.listdir(image_folder))
image_files = []
for root, _, files in os.walk(image_folder):
    for file in files:
        if file.lower().endswith(('.png', '.jpg', '.jpeg')):
            image_files.append(os.path.join(root, file))
if not image_files:
    print(f"Error: No images found in {image_folder}")
    raise ValueError("No images found in the specified folder.")

print(f"Found {len(image_files)} images in the directory.")

preprocessed_images = [preprocess_image(img) for img in image_files]
preprocessed_images = [img for img in preprocessed_images if img is not None]  # Remove None values
# Ensure images are loaded correctly
if not preprocessed_images:
    raise ValueError("No valid images found. Check the image paths.")

# Extract Features
features = extract_features(preprocessed_images)
if features.size == 0:
    raise ValueError("Feature extraction returned an empty array. Check the images and feature extraction function.")

print(f"Feature matrix shape: {features.shape}")  # Debugging

# Perform Feature Selection
if features.shape[0] > 0 and features.shape[1] > 0:
    features_selected = genetic_feature_selection(features, labels)
else:
    raise ValueError("Feature selection cannot proceed due to empty feature matrix.")

best_model = None
best_score = -np.inf

for train_idx, test_idx in kf.split(features_selected, labels):
    X_train, X_test = features_selected[train_idx], features_selected[test_idx]
    y_train, y_test = labels[train_idx], labels[test_idx]

    model = build_unet(input_shape=(224, 224, 1))
    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)
    y_pred_probs = model.predict(X_test)
    y_pred = (y_pred_probs > 0.5).astype(int)

    f1 = f1_score(y_test, y_pred, zero_division=1)
    if f1 > best_score:
        best_score = f1
        best_model = model

print("Best F1-Score:", best_score)