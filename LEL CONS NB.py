# -*- coding: utf-8 -*-
"""07022025 LEL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-AN_S9BQiwL3mg7TfnxFLMKW_dBZwbPz
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import NearMiss
from sklearn.ensemble import VotingClassifier
from sklearn.preprocessing import LabelEncoder
from google.colab import drive

#import data
from google.colab import drive
drive.mount('/content/drive')

# Code to read csv file into Colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'

import pandas as pd
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('cons Labelled Final')
df = pd.read_csv('cons Labelled Final')

df  = df.drop("Unnamed: 0",axis=1)
df = df.drop("minority_count",axis=1)
df = df.drop("majority_count",axis=1)


X = df.drop(["outcome", "label"], axis=1)
y = df["outcome"]

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Function to train and evaluate a model, and return probabilities for precision-recall curve
def train_and_evaluate(model, X_train, y_train, X_test, y_test, label):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]

    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    auroc = roc_auc_score(y_test, y_pred_proba)

    print(f"{label} - Precision: {precision}, Recall: {recall}, F1-score: {f1}, Accuracy: {accuracy}, AUROC: {auroc}")
    precisions, recalls, _ = precision_recall_curve(y_test, y_pred_proba)

    return precisions, recalls

# Standard Naive Bayes (excluding "label" field)
nb = GaussianNB()
nb_precisions, nb_recalls = train_and_evaluate(nb, X_train.drop("label", axis=1, errors='ignore'), y_train, X_test.drop("label", axis=1, errors='ignore'), y_test, "Standard Naive Bayes")

# Naive Bayes with SMOTE (excluding "label" field)
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train.drop("label", axis=1, errors='ignore'), y_train)
nb_smote = GaussianNB()
nb_smote_precisions, nb_smote_recalls = train_and_evaluate(nb_smote, X_train_smote, y_train_smote, X_test.drop("label", axis=1, errors='ignore'), y_test, "Naive Bayes with SMOTE")

# Cost-Sensitive Naive Bayes (excluding "label" field)
nb_cost_sensitive = GaussianNB()
nb_cost_precisions, nb_cost_recalls = train_and_evaluate(nb_cost_sensitive, X_train.drop("label", axis=1, errors='ignore'), y_train, X_test.drop("label", axis=1, errors='ignore'), y_test, "Cost-Sensitive Naive Bayes")

# lel Ensemble Naive Bayes - Label Encoding and Subset Processing (includes "label" field)
le = LabelEncoder()
df["label"] = le.fit_transform(df["label"])  # Encode "label" field if not already encoded

# Split dataset into train and test specifically for LEL ensemble
train, test = train_test_split(df, test_size=0.3, random_state=42)
train["label"] = le.fit_transform(train["label"])
test["label"] = le.transform(test["label"])

# Split the training set into subsets based on "label"
rare = train[train["label"] == 2]
outlier = train[train["label"] == 1]
safe = train[train["label"] == 3]
borderline = train[train["label"] == 0]

# Apply SMOTE to rare and outlier subsets
combined = pd.concat([rare, outlier])
smote = SMOTE(random_state=42, sampling_strategy="auto", k_neighbors=1)

# Apply NearMiss to safe and borderline subsets
ncr = NearMiss(version=1, sampling_strategy="majority", n_neighbors=2)
safe_X, safe_y = ncr.fit_resample(safe.drop("outcome", axis=1), safe["outcome"])
borderline_X, borderline_y = ncr.fit_resample(borderline.drop("outcome", axis=1), borderline["outcome"])
combined_X = combined.drop("outcome", axis=1)
combined_y = combined["outcome"]

# Train Naive Bayes models for ABEL ensemble
nb_safe = GaussianNB()
nb_safe.fit(safe_X, safe_y)
nb_borderline = GaussianNB()
nb_borderline.fit(borderline_X, borderline_y)
nb_combined = GaussianNB()
nb_combined.fit(combined_X, combined_y)

# Ensemble with Voting Classifier for ABEL
ensemble = VotingClassifier(estimators=[('nb_safe', nb_safe), ('nb_borderline', nb_borderline), ('nb_combined', nb_combined)], voting='soft')
ensemble_precisions, ensemble_recalls = train_and_evaluate(ensemble, train.drop("outcome", axis=1), train["outcome"], test.drop("outcome", axis=1), test["outcome"], "BEL Ensemble Naive Bayes")

# Plot Precision-Recall Curves
plt.figure(figsize=(10, 8))
#plt.plot(nb_recalls, nb_precisions, label='Standard Naive Bayes')
plt.plot(nb_smote_recalls, nb_smote_precisions, label='Naive Bayes with SMOTE')
plt.plot(nb_cost_recalls, nb_cost_precisions, label='Naive Bayes with Cost-Sensitive')
plt.plot(ensemble_recalls, ensemble_precisions, label='Naive Bayes with BEL Ensemble')

plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve")
plt.legend(loc="lower left")
plt.show()