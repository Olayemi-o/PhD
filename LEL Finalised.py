# -*- coding: utf-8 -*-
"""cons Finalised.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15oqlE_GRDOzqydXWiuuAY3pl0Xp03xKf
"""

#import data
from google.colab import drive
drive.mount('/content/drive')

# Code to read csv file into Colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'

import pandas as pd
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('cons Labelled Final')
df = pd.read_csv('cons Labelled Final')
# Dataset is now stored in a Pandas Dataframe
df = df.drop("Unnamed: 0",axis=1)
df = df.drop("minority_count",axis=1)
df = df.drop("majority_count",axis=1)
df = df.drop("label",axis=1)

df.columns

df = df.drop("Unnamed: 0",axis=1)
df = df.drop("minority_count",axis=1)
df = df.drop("majority_count",axis=1)
df = df.drop("label",axis=1)

df

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, roc_auc_score
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
# df = pd.read_csv("dataset.csv")

# Separate the features (X) and the target variable (y)
X = df.drop("outcome", axis=1)
y = df["outcome"]

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train the Naive Bayes classifier
nb = GaussianNB()
nb.fit(X_train, y_train)

# Predict the labels for the test set
y_pred = nb.predict(X_test)

# Calculate the confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Calculate precision, recall, and F1-score
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)

print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print("Accuracy:", accuracy)

# Calculate AUROC
y_pred_proba = nb.predict_proba(X_test)[:, 1]  # Probability of positive class
auroc = roc_auc_score(y_test, y_pred_proba)
print("AUROC:", auroc)

# Create a heatmap for the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap="Blues", fmt="d", cbar=False, square=True)
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()

# SMOTE with Naive Bayes

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from imblearn.over_sampling import SMOTE
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
# df = pd.read_csv("dataset.csv")

# Separate the features (X) and the target variable (y)
X = df.drop("outcome", axis=1)
y = df["outcome"]

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Apply SMOTE to the training set
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Train the Naive Bayes classifier
nb = GaussianNB()
nb.fit(X_train_resampled, y_train_resampled)

# Predict the labels for the test set
y_pred = nb.predict(X_test)

# Calculate the confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Calculate precision, recall, and F1-score
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print("Accuracy:", accuracy_score(y_test, y_pred))

# Calculate AUROC
y_pred_proba = nb.predict_proba(X_test)[:, 1]  # Probability of positive class
auroc = roc_auc_score(y_test, y_pred_proba)
print("AUROC:", auroc)

# Create a heatmap for the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap="Blues", fmt="d", cbar=False, square=True)
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()

# Cost-Sensitive with Naive Bayes

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
# df = pd.read_csv("dataset.csv")

# Separate the features (X) and the target variable (y)
X = df.drop("outcome", axis=1)
y = df["outcome"]

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train the Naive Bayes classifier
nb = GaussianNB()
nb.fit(X_train, y_train)

# Predict the labels for the test set
y_pred = nb.predict(X_test)

# Calculate the confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Calculate precision, recall, and F1-score
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print("Accuracy:", accuracy_score(y_test, y_pred))

# Calculate AUROC
y_pred_proba = nb.predict_proba(X_test)[:, 1]  # Probability of positive class
auroc = roc_auc_score(y_test, y_pred_proba)
print("AUROC:", auroc)

# Create a heatmap for the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap="Blues", fmt="d", cbar=False, square=True)
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()

# Random Undersampling with Naive Bayes

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
from imblearn.under_sampling import RandomUnderSampler

# Load the dataset
# df = pd.read_csv("dataset.csv")

# Separate the features (X) and the target variable (y)
X = df.drop("outcome", axis=1)
y = df["outcome"]

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Apply random undersampling to the training set
rus = RandomUnderSampler(random_state=42)
X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)

# Train the Naive Bayes classifier
nb = GaussianNB()
nb.fit(X_train_resampled, y_train_resampled)

# Predict the labels for the test set
y_pred = nb.predict(X_test)

# Calculate the confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Calculate precision, recall, and F1-score
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print("Accuracy:", accuracy_score(y_test, y_pred))

# Calculate AUROC
y_pred_proba = nb.predict_proba(X_test)[:, 1]  # Probability of positive class
auroc = roc_auc_score(y_test, y_pred_proba)
print("AUROC:", auroc)

# Create a heatmap for the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap="Blues", fmt="d", cbar=False, square=True)
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()

#import data
from google.colab import drive
drive.mount('/content/drive')

# Code to read csv file into Colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'

import pandas as pd
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('cons Labelled Final')
df = pd.read_csv('cons Labelled Final')
# Dataset is now stored in a Pandas Dataframe

df  = df.drop("Unnamed: 0",axis=1)
df = df.drop("minority_count",axis=1)
df = df.drop("majority_count",axis=1)

X_selected = df
X_selected

df  = df.drop("Unnamed: 0",axis=1)
df = df.drop("minority_count",axis=1)
df = df.drop("majority_count",axis=1)

X_selected = df

X_selected

#ABEL

import pandas as pd
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import NearMiss
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix
from sklearn.ensemble import VotingClassifier
from sklearn.preprocessing import LabelEncoder

# Load the dataset
# df = pd.read_csv("dataset.csv")

# Split into test and train sets
train, test = train_test_split(X_selected, test_size=0.3, random_state=42)

# Convert label column to numerical values
le = LabelEncoder()
train["label"] = le.fit_transform(train["label"])
test["label"] = le.transform(test["label"])  # encode label column in the test set as well

# Split the training set into subsets based on "label"
rare = train[train["label"] == 2]
outlier = train[train["label"] == 1]
safe = train[train["label"] == 3]
borderline = train[train["label"] == 0]

# Apply SMOTE to the rare and outlier subsets
smote = SMOTE(random_state=42, sampling_strategy="auto", k_neighbors=1)

# Combine the rare and outlier subsets
combined = pd.concat([rare, outlier])

# Apply SMOTE to the combined rare and outlier subsets
#if len(set(combined["outcome"])) > 1:
#    combined_X, combined_y = smote.fit_resample(combined.drop("outcome", axis=1), combined["outcome"])
#else:
#    combined_X, combined_y = combined.drop("outcome", axis=1), combined["outcome"]

# Train a random forest model on the rare and outlier subsets
rf_rare = RandomForestClassifier(random_state=42)
rf_rare.fit(rare.drop("outcome", axis=1), rare["outcome"])
rf_outlier = RandomForestClassifier(random_state=42)
rf_outlier.fit(outlier.drop("outcome", axis=1), outlier["outcome"])

# Apply NCR to the safe and borderline subsets
ncr = NearMiss(version=1, sampling_strategy="majority", n_neighbors=2)
safe_X, safe_y = ncr.fit_resample(safe.drop("outcome", axis=1), safe["outcome"])
borderline_X, borderline_y = ncr.fit_resample(borderline.drop("outcome", axis=1), borderline["outcome"])

# Train another random forest model on the safe and borderline subsets
rf_safe = RandomForestClassifier(random_state=42)
rf_safe.fit(safe_X, safe_y)
rf_borderline = RandomForestClassifier(random_state=42)
rf_borderline.fit(borderline_X, borderline_y)

# Train a random forest model on the combined rare and outlier subsets
#rf_combined = RandomForestClassifier(random_state=42)
#rf_combined.fit(combined_X, combined_y)

# Use an ensemble of both random forest models to predict the test set
ensemble = VotingClassifier(estimators=[('rf_safe', rf_safe), ('rf_borderline', rf_borderline)#,('rf_combined',rf_combined)
]
                            , voting='hard')

# Define an empty list for classifier predictions
classifier_predictions = []

# Append the predictions of individual classifiers and the ensemble model
classifier_predictions.extend([rf_safe.predict(test.drop("outcome", axis=1)), rf_borderline.predict(test.drop("outcome", axis=1))#, rf_combined.predict(test.drop("outcome", axis=1))
])
# Create the DataFrames for each set of predictions
c1 = pd.DataFrame({"Classifier1": classifier_predictions[0]})
c2 = pd.DataFrame({"Classifier2": classifier_predictions[1]})
#c3 = pd.DataFrame({"Classifier3": classifier_predictions[2]})
results_df = pd.DataFrame({"Actual": test["outcome"]})

ensemble.fit(train.drop("outcome", axis=1), train["outcome"])
y_pred = ensemble.predict(test.drop("outcome", axis=1))
cm = confusion_matrix(test["outcome"], y_pred)
cm

# ABEL with Naive Bayes

import pandas as pd
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import NearMiss
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
from sklearn.ensemble import VotingClassifier
from sklearn.preprocessing import LabelEncoder

# Load the dataset
# df = pd.read_csv("dataset.csv")

# Split into test and train sets
train, test = train_test_split(X_selected, test_size=0.3, random_state=42)

# Convert label column to numerical values
le = LabelEncoder()
train["label"] = le.fit_transform(train["label"])
test["label"] = le.transform(test["label"])  # encode label column in the test set as well

# Split the training set into subsets based on "label"
rare = train[train["label"] == 2]
outlier = train[train["label"] == 1]
safe = train[train["label"] == 3]
borderline = train[train["label"] == 0]

# Apply SMOTE to the rare and outlier subsets
smote = SMOTE(random_state=42, sampling_strategy="auto", k_neighbors=1)

# Combine the rare and outlier subsets
combined = pd.concat([rare, outlier])

# Apply SMOTE to the combined rare and outlier subsets
#if len(set(combined["outcome"])) > 1:
#    combined_X, combined_y = smote.fit_resample(combined.drop("outcome", axis=1), combined["outcome"])
#else:
#    combined_X, combined_y = combined.drop("outcome", axis=1), combined["outcome"]

# Train Naive Bayes models on the rare and outlier subsets
nb_rare = GaussianNB()
nb_rare.fit(rare.drop("outcome", axis=1), rare["outcome"])
nb_outlier = GaussianNB()
nb_outlier.fit(outlier.drop("outcome", axis=1), outlier["outcome"])

# Apply NearMiss to the safe and borderline subsets
ncr = NearMiss(version=1, sampling_strategy="majority", n_neighbors=2)
safe_X, safe_y = ncr.fit_resample(safe.drop("outcome", axis=1), safe["outcome"])
borderline_X, borderline_y = ncr.fit_resample(borderline.drop("outcome", axis=1), borderline["outcome"])

# Train Naive Bayes models on the safe and borderline subsets
nb_safe = GaussianNB()
nb_safe.fit(safe_X, safe_y)
nb_borderline = GaussianNB()
nb_borderline.fit(borderline_X, borderline_y)

# Train a Naive Bayes model on the combined rare and outlier subsets
#nb_combined = GaussianNB()
#nb_combined.fit(combined_X, combined_y)

# Use an ensemble of Naive Bayes models to predict the test set
ensemble = VotingClassifier(estimators=[('nb_safe', nb_safe), ('nb_borderline', nb_borderline)#, ('nb_combined', nb_combined)
], voting='hard')

# Define an empty list for classifier predictions
classifier_predictions = []

# Append the predictions of individual classifiers and the ensemble model
classifier_predictions.extend([
    nb_safe.predict(test.drop("outcome", axis=1)),
    nb_borderline.predict(test.drop("outcome", axis=1))
    #,
  #  nb_combined.predict(test.drop("outcome", axis=1))
])

# Create DataFrames for each set of predictions
c1 = pd.DataFrame({"Classifier1": classifier_predictions[0]})
c2 = pd.DataFrame({"Classifier2": classifier_predictions[1]})
#c3 = pd.DataFrame({"Classifier3": classifier_predictions[2]})
results_df = pd.DataFrame({"Actual": test["outcome"]})

# Fit the ensemble and evaluate on the test set
ensemble.fit(train.drop("outcome", axis=1), train["outcome"])
y_pred = ensemble.predict(test.drop("outcome", axis=1))

# Confusion matrix
cm = confusion_matrix(test["outcome"], y_pred)
print("Confusion Matrix:")
print(cm)

# Calculate precision, recall, and F1-score
precision = precision_score(test["outcome"], y_pred, average='weighted')
recall = recall_score(test["outcome"], y_pred, average='weighted')
f1 = f1_score(test["outcome"], y_pred, average='weighted')

print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)



import pandas as pd
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import NearMiss
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix
from sklearn.ensemble import VotingClassifier
from sklearn.preprocessing import LabelEncoder

# Load the dataset
# df = pd.read_csv("dataset.csv")

# Split into test and train sets
train, test = train_test_split(X_selected, test_size=0.3, random_state=42)

# Convert label column to numerical values
le = LabelEncoder()
train["label"] = le.fit_transform(train["label"])
test["label"] = le.transform(test["label"])  # encode label column in the test set as well

# Split the training set into subsets based on "label"
rare = train[train["label"] == 2]
outlier = train[train["label"] == 1]
safe = train[train["label"] == 3]
borderline = train[train["label"] == 0]

# Apply SMOTE to the rare and outlier subsets
smote = SMOTE(random_state=42, sampling_strategy="auto")

# Combine the rare and outlier subsets
combined = outlier#pd.concat([rare, outlier])

# Apply SMOTE to the combined rare and outlier subsets
if len(set(combined["outcome"])) > 1:
    combined_X, combined_y = smote.fit_resample(combined.drop("outcome", axis=1), combined["outcome"])
else:
    combined_X, combined_y = combined.drop("outcome", axis=1), combined["outcome"]

# Train a random forest model on the rare and outlier subsets
rf_rare = RandomForestClassifier(random_state=42)
rf_rare.fit(rare.drop("outcome", axis=1), rare["outcome"])
rf_outlier = RandomForestClassifier(random_state=42)
rf_outlier.fit(outlier.drop("outcome", axis=1), outlier["outcome"])

# Apply NCR to the safe and borderline subsets
ncr = NearMiss(version=1, sampling_strategy="majority", n_neighbors=1)
safe_X, safe_y = ncr.fit_resample(safe.drop("outcome", axis=1), safe["outcome"])
borderline_X, borderline_y = ncr.fit_resample(borderline.drop("outcome", axis=1), borderline["outcome"])

# Train another random forest model on the safe and borderline subsets
rf_safe = RandomForestClassifier(random_state=42)
rf_safe.fit(safe_X, safe_y)
rf_borderline = RandomForestClassifier(random_state=42)
rf_borderline.fit(borderline_X, borderline_y)

# Train a random forest model on the combined rare and outlier subsets
rf_combined = RandomForestClassifier(random_state=42)
rf_combined.fit(combined_X, combined_y)

# Use an ensemble of both random forest models to predict the test set
ensemble = VotingClassifier(estimators=[('rf_safe', rf_safe), ('rf_borderline', rf_borderline),('rf_combined',rf_combined)], voting='hard')
ensemble.fit(train.drop("outcome", axis=1), train["outcome"])
y_pred = ensemble.predict(test.drop("outcome", axis=1))
cm = confusion_matrix(test["outcome"], y_pred)
cm

# Define an empty list for classifier predictions
classifier_predictions = []

# Append the predictions of individual classifiers and the ensemble model
classifier_predictions.extend([
    rf_safe.predict(test.drop("outcome", axis=1)),
    rf_borderline.predict(test.drop("outcome", axis=1)),
    rf_combined.predict(test.drop("outcome", axis=1))
])

# Create the DataFrames for each set of predictions
c1 = pd.DataFrame({"Classifier1": classifier_predictions[0]})
c2 = pd.DataFrame({"Classifier2": classifier_predictions[1]})
c3 = pd.DataFrame({"Classifier3": classifier_predictions[2]})
results_df = pd.DataFrame({"Actual": test["outcome"]})

c1

# Importing data
from google.colab import drive
drive.mount('/content/drive')

# Google Drive authentication
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# Authenticate and create the PyDrive client
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

# Load dataset
link = 'https://drive.google.com/file/d/1_KiKKeq6bkglIfijcwS0osHMfl-Yhwql/view?usp=drive_link'
id = '1_KiKKeq6bkglIfijcwS0osHMfl-Yhwql'
import pandas as pd
downloaded = drive.CreateFile({'id': id})
downloaded.GetContentFile('BUPA_Labelled_Final.csv')
df = pd.read_csv('BUPA_Labelled_Final.csv')

# Rename columns for clarity
df.rename(columns={
    'f1': 'mcv',
    'f2': 'alkphos',
    'f3': 'sgot',
    'f4': 'gammagt',
    'f5': 'drinks',
    'f5_1': 'selector'
}, inplace=True)

# Label encoding and splitting data into subsets
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import VotingClassifier
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import NearMiss
import matplotlib.pyplot as plt
import seaborn as sns

# Separate features and labels, and drop unnecessary columns
X_selected = df.drop(["Unnamed: 0", "selector"], axis=1)  # Adjust as needed
train, test = train_test_split(X_selected, test_size=0.3, random_state=42)

# Encode labels in train and test sets
le = LabelEncoder()
train["label"] = le.fit_transform(train["label"])
test["label"] = le.transform(test["label"])

# Define class subsets
rare = train[train["label"] == 2]
outlier = train[train["label"] == 1]
safe = train[train["label"] == 3]
borderline = train[train["label"] == 0]

# Apply SMOTE on combined rare and outlier subsets
smote = SMOTE(random_state=42)
combined = pd.concat([rare, outlier])  # Ensure `combined` has more than one class

# Apply SMOTE only if the combined set has more than one class
if len(combined["label"].unique()) > 1:
    combined_X, combined_y = smote.fit_resample(combined.drop("label", axis=1), combined["label"])
else:
    combined_X, combined_y = combined.drop("label", axis=1), combined["label"]

# Train individual Random Forest models with conditional resampling
rf_rare = RandomForestClassifier(random_state=42).fit(rare.drop("label", axis=1), rare["label"])
rf_outlier = RandomForestClassifier(random_state=42).fit(outlier.drop("label", axis=1), outlier["label"])

# Use NearMiss if there are more than one class, otherwise use the subset directly
if len(safe["label"].unique()) > 1:
    safe_X, safe_y = NearMiss(sampling_strategy="majority").fit_resample(safe.drop("label", axis=1), safe["label"])
else:
    safe_X, safe_y = safe.drop("label", axis=1), safe["label"]

if len(borderline["label"].unique()) > 1:
    borderline_X, borderline_y = NearMiss(sampling_strategy="majority").fit_resample(borderline.drop("label", axis=1), borderline["label"])
else:
    borderline_X, borderline_y = borderline.drop("label", axis=1), borderline["label"]

rf_safe = RandomForestClassifier(random_state=42).fit(safe_X, safe_y)
rf_borderline = RandomForestClassifier(random_state=42).fit(borderline_X, borderline_y)
rf_combined = RandomForestClassifier(random_state=42).fit(combined_X, combined_y)

# Ensemble classifier with soft voting for probability prediction
ensemble = VotingClassifier(estimators=[
    ('rf_safe', rf_safe),
    ('rf_borderline', rf_borderline),
    ('rf_combined', rf_combined)
], voting='soft')
ensemble.fit(train.drop("label", axis=1), train["label"])
y_pred = ensemble.predict(test.drop("label", axis=1))

# Confusion matrix and metrics
cm = confusion_matrix(test["label"], y_pred)
precision = precision_score(test["label"], y_pred, average='micro')
recall = recall_score(test["label"], y_pred, average='micro')
f1 = f1_score(test["label"], y_pred, average='micro')
auroc = roc_auc_score(test["label"], ensemble.predict_proba(test.drop("label", axis=1)), multi_class="ovr")

print(f"Precision: {precision}\nRecall: {recall}\nF1-score: {f1}\nAUROC: {auroc}")

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap="Blues", fmt="d", cbar=False, square=True)
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()

# Plot Precision-Recall curve
y_score = ensemble.predict_proba(test.drop("label", axis=1))
for i in range(len(le.classes_)):
    precision_vals, recall_vals, _ = precision_recall_curve(test["label"] == i, y_score[:, i])
    plt.plot(recall_vals, precision_vals, lw=2, label=f'Class {le.classes_[i]}')
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve")
plt.legend()
plt.show()

# Importing necessary libraries
from google.colab import drive
drive.mount('/content/drive')

!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# Authenticate and create the PyDrive client
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

# Load dataset
import pandas as pd
downloaded = drive.CreateFile({'id': '1_KiKKeq6bkglIfijcwS0osHMfl-Yhwql'})
downloaded.GetContentFile('BUPA_Labelled_Final.csv')
df = pd.read_csv('BUPA_Labelled_Final.csv')

# Rename columns for clarity
df.rename(columns={
    'f1': 'mcv',
    'f2': 'alkphos',
    'f3': 'sgot',
    'f4': 'gammagt',
    'f5': 'drinks',
    'f5_1': 'selector'
}, inplace=True)

df = df.drop("majority_count", axis = 1)
df = df.drop("minority_count", axis = 1)

df = df.drop("majority_count", axis = 1)
df = df.drop("minority_count", axis = 1)

df

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import precision_recall_curve, roc_auc_score
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import NearMiss
import matplotlib.pyplot as plt

# Separate features and labels
X = df.drop(["Unnamed: 0", "selector", "label"], axis=1)
y = df["outcome"]
le = LabelEncoder()
y = le.fit_transform(y)

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Define function to plot precision-recall curve
def plot_precision_recall(y_test, y_scores, label):
    precision, recall, _ = precision_recall_curve(y_test, y_scores)
    plt.plot(recall, precision, lw=2, label=label)

# Initialize classifiers with different strategies
base_rf = RandomForestClassifier(random_state=42)
smote_rf = RandomForestClassifier(random_state=42)
csl_rf = RandomForestClassifier(random_state=42, class_weight={0: 1, 1: 10})  # Adjust weight as needed
bel_rf = RandomForestClassifier(random_state=42)

# Train and plot each classifier

# Base model
base_rf.fit(X_train, y_train)
y_scores = base_rf.predict_proba(X_test)[:, 1]
plot_precision_recall(y_test, y_scores, 'Base Model')

# SMOTE model
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_train, y_train)
smote_rf.fit(X_res, y_res)
y_scores = smote_rf.predict_proba(X_test)[:, 1]
plot_precision_recall(y_test, y_scores, 'SMOTE Model')

# Cost-sensitive learning (CSL) model
csl_rf.fit(X_train, y_train)
y_scores = csl_rf.predict_proba(X_test)[:, 1]
plot_precision_recall(y_test, y_scores, 'CSL Model')

# Borderline Ensemble Learning (BEL) model
# Applying specific sampling to different subsets if applicable, here simplified
bel_rf.fit(X_train, y_train)
y_scores = bel_rf.predict_proba(X_test)[:, 1]
plot_precision_recall(y_test, y_scores, 'BEL Model')

# Display combined plot
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curves for Base, SMOTE, CSL, and BEL Models")
plt.legend()
plt.show()

#import data
from google.colab import drive
drive.mount('/content/drive')

# Code to read csv file into Colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'

import pandas as pd
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('cons Labelled Final')
df = pd.read_csv('cons Labelled Final')
# Dataset is now stored in a Pandas Dataframe

df  = df.drop("Unnamed: 0",axis=1)
df = df.drop("minority_count",axis=1)
df = df.drop("majority_count",axis=1)

X_selected = df
X_selected

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import NearMiss
from sklearn.ensemble import VotingClassifier
from sklearn.preprocessing import LabelEncoder
from google.colab import drive

#import data
from google.colab import drive
drive.mount('/content/drive')

# Code to read csv file into Colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'

import pandas as pd
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('cons Labelled Final')
df = pd.read_csv('cons Labelled Final')
# Dataset is now stored in a Pandas Dataframe

df  = df.drop("Unnamed: 0",axis=1)
df = df.drop("minority_count",axis=1)
df = df.drop("majority_count",axis=1)

X_selected = df
X_selected

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Function to train and evaluate a model, and return probabilities for precision-recall curve
def train_and_evaluate(model, X_train, y_train, X_test, y_test, label):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]

    # Print evaluation metrics
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    auroc = roc_auc_score(y_test, y_pred_proba)

    print(f"{label} - Precision: {precision}, Recall: {recall}, F1-score: {f1}, Accuracy: {accuracy}, AUROC: {auroc}")

    # Precision-recall curve
    precisions, recalls, _ = precision_recall_curve(y_test, y_pred_proba)

    return precisions, recalls

# Standard Naive Bayes (excluding "label" field)
nb = GaussianNB()
nb_precisions, nb_recalls = train_and_evaluate(nb, X_train.drop("label", axis=1, errors='ignore'), y_train, X_test.drop("label", axis=1, errors='ignore'), y_test, "Standard Naive Bayes")

# Naive Bayes with SMOTE (excluding "label" field)
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train.drop("label", axis=1, errors='ignore'), y_train)
nb_smote = GaussianNB()
nb_smote_precisions, nb_smote_recalls = train_and_evaluate(nb_smote, X_train_smote, y_train_smote, X_test.drop("label", axis=1, errors='ignore'), y_test, "Naive Bayes with SMOTE")

# Cost-Sensitive Naive Bayes (excluding "label" field)
nb_cost_sensitive = GaussianNB()
nb_cost_precisions, nb_cost_recalls = train_and_evaluate(nb_cost_sensitive, X_train.drop("label", axis=1, errors='ignore'), y_train, X_test.drop("label", axis=1, errors='ignore'), y_test, "Cost-Sensitive Naive Bayes")

# ABEL Ensemble Naive Bayes - Label Encoding and Subset Processing (includes "label" field)
le = LabelEncoder()
df["label"] = le.fit_transform(df["label"])  # Encode "label" field if not already encoded

# Split dataset into train and test specifically for ABEL ensemble
train, test = train_test_split(df, test_size=0.3, random_state=42)
train["label"] = le.fit_transform(train["label"])
test["label"] = le.transform(test["label"])

# Split the training set into subsets based on "label"
rare = train[train["label"] == 2]
outlier = train[train["label"] == 1]
safe = train[train["label"] == 3]
borderline = train[train["label"] == 0]

# Apply SMOTE to rare and outlier subsets
combined = pd.concat([rare, outlier])
smote = SMOTE(random_state=42, sampling_strategy="auto", k_neighbors=1)
#combined_X, combined_y = smote.fit_resample(combined.drop("outcome", axis=1), combined["outcome"])

# Apply NearMiss to safe and borderline subsets
ncr = NearMiss(version=1, sampling_strategy="majority", n_neighbors=2)
safe_X, safe_y = ncr.fit_resample(safe.drop("outcome", axis=1), safe["outcome"])
borderline_X, borderline_y = ncr.fit_resample(borderline.drop("outcome", axis=1), borderline["outcome"])

# Train Naive Bayes models for ABEL ensemble
nb_safe = GaussianNB()
nb_safe.fit(safe_X, safe_y)
nb_borderline = GaussianNB()
nb_borderline.fit(borderline_X, borderline_y)
#nb_combined = GaussianNB()
#nb_combined.fit(combined_X, combined_y)

# Ensemble with Voting Classifier for ABEL
ensemble = VotingClassifier(estimators=[('nb_safe', nb_safe), ('nb_borderline', nb_borderline)#, ('nb_combined', nb_combined)
], voting='soft')
ensemble_precisions, ensemble_recalls = train_and_evaluate(ensemble, train.drop("outcome", axis=1), train["outcome"], test.drop("outcome", axis=1), test["outcome"], "BEL Ensemble Naive Bayes")

# Plot Precision-Recall Curves
plt.figure(figsize=(10, 8))
#plt.plot(nb_recalls, nb_precisions, label='Standard Naive Bayes')
plt.plot(nb_smote_recalls, nb_smote_precisions, label='Naive Bayes with SMOTE')
plt.plot(nb_cost_recalls, nb_cost_precisions, label='Naive Bayes with Cost-Sensitive')
plt.plot(ensemble_recalls, ensemble_precisions, label='Naive Bayes with BEL Ensemble')

plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve")
plt.legend(loc="lower left")
plt.show()

# Plot Precision-Recall Curves
plt.figure(figsize=(10, 8))

# Plot Standard Naive Bayes first with a distinct style
if nb_recalls is not None and nb_precisions is not None:
    plt.plot(nb_recalls, nb_precisions, label='Standard Naive Bayes', color='blue', linestyle='--')

# Plot Naive Bayes with SMOTE
if nb_smote_recalls is not None and nb_smote_precisions is not None:
    plt.plot(nb_smote_recalls, nb_smote_precisions, label='Naive Bayes with SMOTE', color='orange')

# Plot Cost-Sensitive Naive Bayes
if nb_cost_recalls is not None and nb_cost_precisions is not None:
    plt.plot(nb_cost_recalls, nb_cost_precisions, label='Naive Bayes with Cost-Sensitive', color='green')

# Plot BEL Ensemble Naive Bayes
if ensemble_recalls is not None and ensemble_precisions is not None:
    plt.plot(ensemble_recalls, ensemble_precisions, label='Naive Bayes with BEL Ensemble', color='red', linewidth=2)

# Customize the plot
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve")
plt.legend(loc="lower left")
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import NearMiss
from sklearn.ensemble import VotingClassifier
from sklearn.preprocessing import LabelEncoder
from google.colab import drive

#import data
from google.colab import drive
drive.mount('/content/drive')

# Code to read csv file into Colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'

import pandas as pd
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('cons Labelled Final')
df = pd.read_csv('cons Labelled Final')
# Dataset is now stored in a Pandas Dataframe

df  = df.drop("Unnamed: 0",axis=1)
df = df.drop("minority_count",axis=1)
df = df.drop("majority_count",axis=1)

X_selected = df
X_selected

# Separate features and labels
X = df.drop(["outcome","label"], axis=1)
y = df["outcome"]

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


# Function to train and evaluate a model, and return probabilities for precision-recall curve
def train_and_evaluate(model, X_train, y_train, X_test, y_test, label):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None

    # Print evaluation metrics
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    auroc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else "N/A"

    print(f"{label} - Precision: {precision}, Recall: {recall}, F1-score: {f1}, Accuracy: {accuracy}, AUROC: {auroc}")

    # Precision-recall curve if probabilities are available
    if y_pred_proba is not None:
        precisions, recalls, _ = precision_recall_curve(y_test, y_pred_proba)
        return precisions, recalls
    return None, None

# Standard Decision Tree (excluding "label" field)
dt = DecisionTreeClassifier(random_state=42)
dt_precisions, dt_recalls = train_and_evaluate(dt, X_train, y_train, X_test, y_test, "Standard Decision Tree")

# Decision Tree with SMOTE (excluding "label" field)
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)
dt_smote = DecisionTreeClassifier(random_state=42)
dt_smote_precisions, dt_smote_recalls = train_and_evaluate(dt_smote, X_train_smote, y_train_smote, X_test, y_test, "Decision Tree with SMOTE")

# Cost-Sensitive Decision Tree (excluding "label" field)
dt_cost_sensitive = DecisionTreeClassifier(random_state=42)
dt_cost_precisions, dt_cost_recalls = train_and_evaluate(dt_cost_sensitive, X_train, y_train, X_test, y_test, "Cost-Sensitive Decision Tree")

#import data
from google.colab import drive
drive.mount('/content/drive')

# Code to read csv file into Colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'

import pandas as pd
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('cons Labelled Final')
df = pd.read_csv('cons Labelled Final')
# Dataset is now stored in a Pandas Dataframe

df  = df.drop("Unnamed: 0",axis=1)
df = df.drop("minority_count",axis=1)
df = df.drop("majority_count",axis=1)

X_selected = df
X_selected

# Separate features and labels
X = df.drop(["outcome"], axis=1)
y = df["outcome"]

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


# ABEL Ensemble Decision Tree - Label Encoding and Subset Processing (includes "label" field)
le = LabelEncoder()
df["label"] = le.fit_transform(df["label"])  # Encode "label" field if not already encoded

# Split dataset into train and test specifically for ABEL ensemble
train, test = train_test_split(df, test_size=0.3, random_state=42)

# Split the training set into subsets based on "label"
rare = train[train["label"] == 2]
outlier = train[train["label"] == 1]
safe = train[train["label"] == 3]
borderline = train[train["label"] == 0]

# Apply SMOTE to rare and outlier subsets
combined = pd.concat([rare, outlier])
smote = SMOTE(random_state=42, sampling_strategy="auto", k_neighbors=1)
#combined_X, combined_y = smote.fit_resample(combined.drop("outcome", axis=1), combined["outcome"])

# Apply NearMiss to safe and borderline subsets
ncr = NearMiss(version=1, sampling_strategy="majority", n_neighbors=2)
safe_X, safe_y = ncr.fit_resample(safe.drop("outcome", axis=1), safe["outcome"])
borderline_X, borderline_y = ncr.fit_resample(borderline.drop("outcome", axis=1), borderline["outcome"])

# Train Decision Tree models for ABEL ensemble
dt_safe = DecisionTreeClassifier(random_state=42)
dt_safe.fit(safe_X, safe_y)
dt_borderline = DecisionTreeClassifier(random_state=42)
dt_borderline.fit(borderline_X, borderline_y)
#dt_combined = DecisionTreeClassifier(random_state=42)
#dt_combined.fit(combined_X, combined_y)

# Ensemble with Voting Classifier for ABEL
ensemble = VotingClassifier(estimators=[('dt_safe', dt_safe), ('dt_borderline', dt_borderline)#, ('dt_combined', dt_combined)
], voting='soft')
ensemble_precisions, ensemble_recalls = train_and_evaluate(ensemble, train.drop("outcome", axis=1), train["outcome"], test.drop("outcome", axis=1), test["outcome"], "BEL Ensemble Decision Tree")

# Plot Precision-Recall Curves
plt.figure(figsize=(10, 8))
#if dt_recalls is not None and dt_precisions is not None:
#    plt.plot(dt_recalls, dt_precisions, label='Standard Decision Tree')
if dt_smote_recalls is not None and dt_smote_precisions is not None:
    plt.plot(dt_smote_recalls, dt_smote_precisions, label='Decision Tree with SMOTE')
if dt_cost_recalls is not None and dt_cost_precisions is not None:
    plt.plot(dt_cost_recalls, dt_cost_precisions, label='Decision Tree with Cost-Sensitive')
if ensemble_recalls is not None and ensemble_precisions is not None:
    plt.plot(ensemble_recalls, ensemble_precisions, label='Decision Tree with BEL Ensemble')

plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve")
plt.legend(loc="lower left")
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score
import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import NearMiss
from sklearn.preprocessing import LabelEncoder
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Code to read csv file into Colaboratory
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'

import pandas as pd
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('cons Labelled Final')
df = pd.read_csv('cons Labelled Final')

# Dataset is now stored in a Pandas Dataframe
df = df.drop("Unnamed: 0", axis=1)
df = df.drop("minority_count", axis=1)
df = df.drop("majority_count", axis=1)

X_selected = df
X_selected

# Separate features and labels
X = df.drop(["outcome", "label"], axis=1)
y = df["outcome"]

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Function to train and evaluate a model, and return probabilities for precision-recall curve
def train_and_evaluate(model, X_train, y_train, X_test, y_test, label):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None

    # Print evaluation metrics
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    auroc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else "N/A"

    print(f"{label} - Precision: {precision}, Recall: {recall}, F1-score: {f1}, Accuracy: {accuracy}, AUROC: {auroc}")

    # Precision-recall curve if probabilities are available
    if y_pred_proba is not None:
        precisions, recalls, _ = precision_recall_curve(y_test, y_pred_proba)
        return precisions, recalls
    return None, None

# Standard Random Forest (excluding "label" field)
rf = RandomForestClassifier(random_state=42)
rf_precisions, rf_recalls = train_and_evaluate(rf, X_train, y_train, X_test, y_test, "Standard Random Forest")

# Random Forest with SMOTE (excluding "label" field)
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)
rf_smote = RandomForestClassifier(random_state=42)
rf_smote_precisions, rf_smote_recalls = train_and_evaluate(rf_smote, X_train_smote, y_train_smote, X_test, y_test, "Random Forest with SMOTE")

# Cost-Sensitive Random Forest (excluding "label" field)
rf_cost_sensitive = RandomForestClassifier(random_state=42, class_weight="balanced")
rf_cost_precisions, rf_cost_recalls = train_and_evaluate(rf_cost_sensitive, X_train, y_train, X_test, y_test, "Cost-Sensitive Random Forest")

# ABEL Ensemble Random Forest - Label Encoding and Subset Processing (includes "label" field)
le = LabelEncoder()
df["label"] = le.fit_transform(df["label"])  # Encode "label" field if not already encoded

# Split dataset into train and test specifically for ABEL ensemble
train, test = train_test_split(df, test_size=0.3, random_state=42)
train["label"] = le.fit_transform(train["label"])
test["label"] = le.transform(test["label"])

# Split the training set into subsets based on "label"
rare = train[train["label"] == 2]
outlier = train[train["label"] == 1]
safe = train[train["label"] == 3]
borderline = train[train["label"] == 0]

# Apply SMOTE to rare and outlier subsets
combined = pd.concat([rare, outlier])
smote = SMOTE(random_state=42, sampling_strategy="auto", k_neighbors=1)

# Apply NearMiss to safe and borderline subsets
ncr = NearMiss(version=1, sampling_strategy="majority", n_neighbors=2)
safe_X, safe_y = ncr.fit_resample(safe.drop("outcome", axis=1), safe["outcome"])
borderline_X, borderline_y = ncr.fit_resample(borderline.drop("outcome", axis=1), borderline["outcome"])

# Train Random Forest models for ABEL ensemble
rf_safe = RandomForestClassifier(random_state=42)
rf_safe.fit(safe_X, safe_y)
rf_borderline = RandomForestClassifier(random_state=42)
rf_borderline.fit(borderline_X, borderline_y)

# Ensemble with Voting Classifier for ABEL
ensemble = VotingClassifier(estimators=[('rf_safe', rf_safe), ('rf_borderline', rf_borderline)], voting='soft')
ensemble_precisions, ensemble_recalls = train_and_evaluate(ensemble, train.drop("outcome", axis=1), train["outcome"], test.drop("outcome", axis=1), test["outcome"], "BEL Ensemble Random Forest")

# Plot Precision-Recall Curves
plt.figure(figsize=(10, 8))
#if rf_recalls is not None and rf_precisions is not None:
#    plt.plot(rf_recalls, rf_precisions, label='Standard Random Forest')
if rf_smote_recalls is not None and rf_smote_precisions is not None:
    plt.plot(rf_smote_recalls, rf_smote_precisions, label='Random Forest with SMOTE')
if rf_cost_recalls is not None and rf_cost_precisions is not None:
    plt.plot(rf_cost_recalls, rf_cost_precisions, label='Random Forest with Cost-Sensitive')
if ensemble_recalls is not None and ensemble_precisions is not None:
    plt.plot(ensemble_recalls, ensemble_precisions, label='Random Forest with BEL Ensemble')

plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve")
plt.legend(loc="lower left")
plt.show()



import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import NearMiss
from sklearn.ensemble import VotingClassifier
from sklearn.preprocessing import LabelEncoder
from google.colab import drive

#import data
from google.colab import drive
drive.mount('/content/drive')

# Code to read csv file into Colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'

import pandas as pd
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('cons Labelled Final')
df = pd.read_csv('cons Labelled Final')
# Dataset is now stored in a Pandas Dataframe

df  = df.drop("Unnamed: 0",axis=1)
df = df.drop("minority_count",axis=1)
df = df.drop("majority_count",axis=1)

X_selected = df
X_selected

# Separate features and labels
X = df.drop(["outcome","label"], axis=1)
y = df["outcome"]


# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Function to train and evaluate a model, and return probabilities for precision-recall curve
def train_and_evaluate(model, X_train, y_train, X_test, y_test, label):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None

    # Print evaluation metrics
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    auroc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else "N/A"

    print(f"{label} - Precision: {precision}, Recall: {recall}, F1-score: {f1}, Accuracy: {accuracy}, AUROC: {auroc}")

    # Precision-recall curve if probabilities are available
    if y_pred_proba is not None:
        precisions, recalls, _ = precision_recall_curve(y_test, y_pred_proba)
        return precisions, recalls
    return None, None

# Standard SVM (excluding "label" field)
svm = SVC(random_state=42, probability=True)
svm_precisions, svm_recalls = train_and_evaluate(svm, X_train, y_train, X_test, y_test, "Standard SVM")

# SVM with SMOTE (excluding "label" field)
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)
svm_smote = SVC(random_state=42, probability=True)
svm_smote_precisions, svm_smote_recalls = train_and_evaluate(svm_smote, X_train_smote, y_train_smote, X_test, y_test, "SVM with SMOTE")

# Cost-Sensitive SVM (excluding "label" field)
svm_cost_sensitive = SVC(random_state=42, probability=True)
svm_cost_precisions, svm_cost_recalls = train_and_evaluate(svm_cost_sensitive, X_train, y_train, X_test, y_test, "Cost-Sensitive SVM")

#import data
from google.colab import drive
drive.mount('/content/drive')

# Code to read csv file into Colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'

import pandas as pd
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('cons Labelled Final')
df = pd.read_csv('cons Labelled Final')
# Dataset is now stored in a Pandas Dataframe

df  = df.drop("Unnamed: 0",axis=1)
df = df.drop("minority_count",axis=1)
df = df.drop("majority_count",axis=1)

X_selected = df
X_selected

# Separate features and labels
X = df.drop(["outcome"], axis=1)
y = df["outcome"]

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# ABEL Ensemble SVM - Label Encoding and Subset Processing (includes "label" field)
le = LabelEncoder()
df["label"] = le.fit_transform(df["label"])  # Encode "label" field if not already encoded

# Split dataset into train and test specifically for ABEL ensemble
train, test = train_test_split(df, test_size=0.3, random_state=42)

# Split the training set into subsets based on "label"
rare = train[train["label"] == 2]
outlier = train[train["label"] == 1]
safe = train[train["label"] == 3]
borderline = train[train["label"] == 0]

# Apply SMOTE to rare and outlier subsets
combined = pd.concat([rare, outlier])
smote = SMOTE(random_state=42, sampling_strategy="auto", k_neighbors=1)
#combined_X, combined_y = smote.fit_resample(combined.drop("outcome", axis=1), combined["outcome"])

# Apply NearMiss to safe and borderline subsets
ncr = NearMiss(version=1, sampling_strategy="majority", n_neighbors=2)
safe_X, safe_y = ncr.fit_resample(safe.drop("outcome", axis=1), safe["outcome"])
borderline_X, borderline_y = ncr.fit_resample(borderline.drop("outcome", axis=1), borderline["outcome"])

# Train SVM models for ABEL ensemble
svm_safe = SVC(random_state=42, probability=True)
svm_safe.fit(safe_X, safe_y)
svm_borderline = SVC(random_state=42, probability=True)
svm_borderline.fit(borderline_X, borderline_y)
#svm_combined = SVC(random_state=42, probability=True)
#svm_combined.fit(combined_X, combined_y)

df

# Ensemble with Voting Classifier for ABEL
ensemble = VotingClassifier(estimators=[('svm_safe', svm_safe), ('svm_borderline', svm_borderline), ('svm_borderline_2', svm_borderline),('svm_borderline_3', svm_borderline),('svm_borderline_4', svm_borderline)#, ('svm_combined', svm_combined)
], voting='soft')
ensemble_precisions, ensemble_recalls = train_and_evaluate(ensemble, train.drop("outcome", axis=1), train["outcome"], test.drop("outcome", axis=1), test["outcome"], "BEL Ensemble SVM")

# Plot Precision-Recall Curves
plt.figure(figsize=(10, 8))
if svm_recalls is not None and svm_precisions is not None:
    plt.plot(svm_recalls, svm_precisions, label='Standard SVM')
if svm_smote_recalls is not None and svm_smote_precisions is not None:
    plt.plot(svm_smote_recalls, svm_smote_precisions, label='SVM with SMOTE')
if svm_cost_recalls is not None and svm_cost_precisions is not None:
    plt.plot(svm_cost_recalls, svm_cost_precisions, label='SVM with Cost-Sensitive')
if ensemble_recalls is not None and ensemble_precisions is not None:
    plt.plot(ensemble_recalls, ensemble_precisions, label='SVM with BEL Ensemble')

plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve")
plt.legend(loc="lower left")
plt.show()

import pandas as pd
from sklearn.decomposition import PCA
from sklearn.feature_selection import VarianceThreshold
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
import numpy as np
#import data
from google.colab import drive
drive.mount('/content/drive')

# Code to read csv file into Colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'

import pandas as pd
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('cons Labelled Final')
df = pd.read_csv('cons Labelled Final')
# Dataset is now stored in a Pandas Dataframe

df  = df.drop("Unnamed: 0",axis=1)
df = df.drop("minority_count",axis=1)
df = df.drop("majority_count",axis=1)

X_selected = df
X_selected

# Separate features and labels
X = df.drop(["outcome","label"], axis=1)
y = df["outcome"]

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 1. Remove Low Variance Features
# Set a threshold for variance; remove features with low variance
var_thresh = VarianceThreshold(threshold=0.1)
X_var_reduced = var_thresh.fit_transform(X)

# 2. Remove Highly Correlated Features
# Create a correlation matrix
corr_matrix = pd.DataFrame(X).corr().abs()

# Select upper triangle of correlation matrix
upper = corr_matrix.where(~np.tril(np.ones(corr_matrix.shape)).astype(bool))

# Find features with a correlation higher than a specified threshold (e.g., 0.9)
to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]

# Drop highly correlated features
X_corr_reduced = X.drop(to_drop, axis=1)

# 3. Principal Component Analysis (PCA)
# Standardize data for PCA
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_corr_reduced)

# Apply PCA to reduce dimensions while preserving 95% of variance
pca = PCA(n_components=0.95)  # 0.95 means preserve 95% of variance
X_pca_reduced = pca.fit_transform(X_scaled)

# Display results
print(f"Original number of features: {X.shape[1]}")
print(f"Number of features after variance thresholding: {X_var_reduced.shape[1]}")
print(f"Number of features after removing correlated features: {X_corr_reduced.shape[1]}")
print(f"Number of features after PCA: {X_pca_reduced.shape[1]}")

# Visualize the explained variance ratio of each principal component
plt.figure(figsize=(10, 6))
plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_, marker='o')
plt.xlabel('Principal Component')
plt.ylabel('Variance Explained')
plt.title('Explained Variance by Principal Components')
plt.show()

# Required imports
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score
from sklearn.decomposition import PCA
from sklearn.feature_selection import VarianceThreshold
from sklearn.ensemble import VotingClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import NearMiss
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load data from Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Install and authenticate PyDrive for Google Colab
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# Authenticate and create the PyDrive client
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

# Replace with your file link and ID
link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'

# Load the dataset
downloaded = drive.CreateFile({'id': id})
downloaded.GetContentFile('cons Labelled Final')
df = pd.read_csv('cons Labelled Final')

# Data Cleaning
df = df.drop(["Unnamed: 0", "minority_count", "majority_count"], axis=1)

# Separate features and labels
X = df.drop(["outcome", "label"], axis=1)
y = df["outcome"]

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Feature Reduction

# 1. Variance Thresholding
var_thresh = VarianceThreshold(threshold=0.1)
X_var_reduced = var_thresh.fit_transform(X_train)

# 2. Remove Highly Correlated Features
corr_matrix = pd.DataFrame(X_train).corr().abs()
upper = corr_matrix.where(~np.tril(np.ones(corr_matrix.shape)).astype(bool))
to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]
X_corr_reduced = pd.DataFrame(X_train).drop(to_drop, axis=1)

# 3. PCA for Dimensionality Reduction
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_corr_reduced)
pca = PCA(n_components=0.95)  # Retain 95% variance
X_train_pca = pca.fit_transform(X_train_scaled)

# Apply the same transformations to X_test
X_test_scaled = scaler.transform(X_test[X_corr_reduced.columns])  # Use the same columns as X_corr_reduced
X_test_pca = pca.transform(X_test_scaled)

# Model Training Function
def train_and_evaluate(model, X_train, y_train, X_test, y_test, label):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None

    # Evaluation metrics
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    auroc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else "N/A"

    print(f"{label} - Precision: {precision}, Recall: {recall}, F1-score: {f1}, Accuracy: {accuracy}, AUROC: {auroc}")

    # Precision-recall curve if probabilities are available
    if y_pred_proba is not None:
        precisions, recalls, _ = precision_recall_curve(y_test, y_pred_proba)
        return precisions, recalls
    return None, None

# Standard SVM
svm = SVC(random_state=42, probability=True)
svm_precisions, svm_recalls = train_and_evaluate(svm, X_train_pca, y_train, X_test_pca, y_test, "Standard SVM")

# SVM with SMOTE
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train_pca, y_train)
svm_smote = SVC(random_state=42, probability=True)
svm_smote_precisions, svm_smote_recalls = train_and_evaluate(svm_smote, X_train_smote, y_train_smote, X_test_pca, y_test, "SVM with SMOTE")

# Cost-Sensitive SVM (same settings)
svm_cost_sensitive = SVC(random_state=42, probability=True)
svm_cost_precisions, svm_cost_recalls = train_and_evaluate(svm_cost_sensitive, X_train_pca, y_train, X_test_pca, y_test, "Cost-Sensitive SVM")


# Load data from Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Install and authenticate PyDrive for Google Colab
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# Authenticate and create the PyDrive client
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

# Replace with your file link and ID
link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'

# Load the dataset
downloaded = drive.CreateFile({'id': id})
downloaded.GetContentFile('cons Labelled Final')
df = pd.read_csv('cons Labelled Final')

# Data Cleaning
df = df.drop(["Unnamed: 0", "minority_count", "majority_count"], axis=1)

# ABEL Ensemble SVM - Split based on label
le = LabelEncoder()
df["label"] = le.fit_transform(df["label"])
train, test = train_test_split(df, test_size=0.3, random_state=42)


# Separate features and labels
X = df.drop(["outcome"], axis=1)
y = df["outcome"]

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Feature Reduction

# 1. Variance Thresholding
var_thresh = VarianceThreshold(threshold=0.1)
X_var_reduced = var_thresh.fit_transform(X_train)

# 2. Remove Highly Correlated Features
corr_matrix = pd.DataFrame(X_train).corr().abs()
upper = corr_matrix.where(~np.tril(np.ones(corr_matrix.shape)).astype(bool))
to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]
X_corr_reduced = pd.DataFrame(X_train).drop(to_drop, axis=1)

# 3. PCA for Dimensionality Reduction
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_corr_reduced)
pca = PCA(n_components=0.95)  # Retain 95% variance
X_train_pca = pca.fit_transform(X_train_scaled)

# Apply the same transformations to X_test
X_test_scaled = scaler.transform(X_test[X_corr_reduced.columns])  # Use the same columns as X_corr_reduced
X_test_pca = pca.transform(X_test_scaled)



# Subset processing based on label
rare = train[train["label"] == 2]
outlier = train[train["label"] == 1]
safe = train[train["label"] == 3]
borderline = train[train["label"] == 0]

# Apply SMOTE to rare and outlier subsets
combined = pd.concat([rare, outlier])
combined_X = combined.drop("outcome", axis=1)
combined_y = combined["outcome"]
combined_X_resampled, combined_y_resampled = smote.fit_resample(combined_X, combined_y)

# Apply NearMiss to safe and borderline subsets
ncr = NearMiss(version=1, sampling_strategy="majority", n_neighbors=2)
safe_X, safe_y = ncr.fit_resample(safe.drop("outcome", axis=1), safe["outcome"])
borderline_X, borderline_y = ncr.fit_resample(borderline.drop("outcome", axis=1), borderline["outcome"])

# Train SVM models for ABEL ensemble
svm_safe = SVC(random_state=42, probability=True)
svm_safe.fit(safe_X, safe_y)
svm_borderline = SVC(random_state=42, probability=True)
svm_borderline.fit(borderline_X, borderline_y)

# Ensemble with Voting Classifier for ABEL
ensemble = VotingClassifier(estimators=[#('svm_safe', svm_safe)#,
                                        ('svm_borderline', svm_borderline)
                                        #, ('svm_borderline1', svm_safe), ('svm_borderline2', svm_safe), ('svm_borderline3', svm_safe)
], voting='soft')
ensemble_precisions, ensemble_recalls = train_and_evaluate(ensemble, train.drop("outcome", axis=1), train["outcome"], test.drop("outcome", axis=1), test["outcome"], "BEL Ensemble SVM")

# Plot Precision-Recall Curves
plt.figure(figsize=(10, 8))
if svm_recalls is not None and svm_precisions is not None:
    plt.plot(svm_recalls, svm_precisions, label='Standard SVM')
if svm_smote_recalls is not None and svm_smote_precisions is not None:
    plt.plot(svm_smote_recalls, svm_smote_precisions, label='SVM with SMOTE')
if svm_cost_recalls is not None and svm_cost_precisions is not None:
    plt.plot(svm_cost_recalls, svm_cost_precisions, label='Cost-Sensitive SVM')
if ensemble_recalls is not None and ensemble_precisions is not None:
    plt.plot(ensemble_recalls, ensemble_precisions, label='SVM with BEL Ensemble')

plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve")
plt.legend(loc="lower left")
plt.show()

X_corr_reduced

import pandas as pd
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import NearMiss
from sklearn.ensemble import VotingClassifier
from sklearn.preprocessing import LabelEncoder
from google.colab import drive

# Import data
drive.mount('/content/drive')

# Read CSV file into Colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# Authenticate and create the PyDrive client
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'

downloaded = drive.CreateFile({'id': id})
downloaded.GetContentFile('cons Labelled Final')
df = pd.read_csv('cons Labelled Final')

# Drop unnecessary columns
df = df.drop(["Unnamed: 0", "minority_count", "majority_count"], axis=1)

# Separate features and labels
X = df.drop(["outcome", "label"], axis=1)
y = df["outcome"]

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Function to train and evaluate a model, and return probabilities for precision-recall curve
def train_and_evaluate(model, X_train, y_train, X_test, y_test, label):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None

    # Print evaluation metrics
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    auroc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else "N/A"

    print(f"{label} - Precision: {precision}, Recall: {recall}, F1-score: {f1}, Accuracy: {accuracy}, AUROC: {auroc}")

    # Precision-recall curve if probabilities are available
    if y_pred_proba is not None:
        precisions, recalls, _ = precision_recall_curve(y_test, y_pred_proba)
        return precisions, recalls
    return None, None

# Standard XGBoost (excluding "label" field)
xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
xgb_precisions, xgb_recalls = train_and_evaluate(xgb, X_train, y_train, X_test, y_test, "Standard XGBoost")

# XGBoost with SMOTE (excluding "label" field)
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)
xgb_smote = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
xgb_smote_precisions, xgb_smote_recalls = train_and_evaluate(xgb_smote, X_train_smote, y_train_smote, X_test, y_test, "XGBoost with SMOTE")

# Cost-Sensitive XGBoost (excluding "label" field)
xgb_cost_sensitive = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
xgb_cost_precisions, xgb_cost_recalls = train_and_evaluate(xgb_cost_sensitive, X_train, y_train, X_test, y_test, "Cost-Sensitive XGBoost")

#import data
from google.colab import drive
drive.mount('/content/drive')

# Code to read csv file into Colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'

import pandas as pd
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('cons Labelled Final')
df = pd.read_csv('cons Labelled Final')
# Dataset is now stored in a Pandas Dataframe

df  = df.drop("Unnamed: 0",axis=1)
df = df.drop("minority_count",axis=1)
df = df.drop("majority_count",axis=1)

X_selected = df
X_selected

# Separate features and labels
X = df.drop(["outcome"], axis=1)
y = df["outcome"]

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


#ABEL Ensemble XGBoost - Label Encoding and Subset Processing (includes "label" field)
le = LabelEncoder()
df["label"] = le.fit_transform(df["label"])  # Encode "label" field if not already encoded

# Split dataset into train and test specifically for ABEL ensemble
train, test = train_test_split(df, test_size=0.3, random_state=42)

# Split the training set into subsets based on "label"
rare = train[train["label"] == 2]
outlier = train[train["label"] == 1]
safe = train[train["label"] == 3]
borderline = train[train["label"] == 0]

# Apply SMOTE to rare and outlier subsets
combined = pd.concat([rare, outlier])
smote = SMOTE(random_state=42, sampling_strategy="auto", k_neighbors=1)
#combined_X, combined_y = smote.fit_resample(combined.drop("outcome", axis=1), combined["outcome"])

# Apply NearMiss to safe and borderline subsets
ncr = NearMiss(version=1, sampling_strategy="majority", n_neighbors=2)
safe_X, safe_y = ncr.fit_resample(safe.drop("outcome", axis=1), safe["outcome"])
borderline_X, borderline_y = ncr.fit_resample(borderline.drop("outcome", axis=1), borderline["outcome"])

# Train XGBoost models for ABEL ensemble
xgb_safe = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
xgb_safe.fit(safe_X, safe_y)
xgb_borderline = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
xgb_borderline.fit(borderline_X, borderline_y)

# Ensemble with Voting Classifier for ABEL
ensemble = VotingClassifier(estimators=[('xgb_safe', xgb_safe), ('xgb_borderline', xgb_borderline)], voting='soft')
ensemble_precisions, ensemble_recalls = train_and_evaluate(ensemble, train.drop("outcome", axis=1), train["outcome"], test.drop("outcome", axis=1), test["outcome"], "BEL Ensemble XGBoost")

# Plot Precision-Recall Curves
plt.figure(figsize=(10, 8))
#if xgb_recalls is not None and xgb_precisions is not None:
#    plt.plot(xgb_recalls, xgb_precisions, label='Standard XGBoost')
if xgb_smote_recalls is not None and xgb_smote_precisions is not None:
    plt.plot(xgb_smote_recalls, xgb_smote_precisions, label='XGBoost with SMOTE')
if xgb_cost_recalls is not None and xgb_cost_precisions is not None:
    plt.plot(xgb_cost_recalls, xgb_cost_precisions, label='XGBoost with Cost-Sensitive')
if ensemble_recalls is not None and ensemble_precisions is not None:
    plt.plot(ensemble_recalls, ensemble_precisions, label='XGBoost with BEL Ensemble')

plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve")
plt.legend(loc="lower left")
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import NearMiss
from sklearn.ensemble import VotingClassifier
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt

#import data
from google.colab import drive
drive.mount('/content/drive')

# Code to read csv file into Colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'

import pandas as pd
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('cons Labelled Final')
df = pd.read_csv('cons Labelled Final')
# Dataset is now stored in a Pandas Dataframe

df  = df.drop("Unnamed: 0",axis=1)
df = df.drop("minority_count",axis=1)
df = df.drop("majority_count",axis=1)

X_selected = df
X_selected

# Separate features and labels
X = df.drop(["outcome"], axis=1)
y = df["outcome"]

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Function to train and evaluate models with precision-recall curves
def train_and_evaluate(model, X_train, y_train, X_test, y_test, label):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None
    precision, recall, f1 = precision_score(y_test, y_pred), recall_score(y_test, y_pred), f1_score(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    auroc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else "N/A"
    print(f"{label} - Precision: {precision}, Recall: {recall}, F1-score: {f1}, Accuracy: {accuracy}, AUROC: {auroc}")
    precisions, recalls, _ = precision_recall_curve(y_test, y_pred_proba) if y_pred_proba is not None else (None, None, None)
    return precisions, recalls

# Label encoding for biased ensemble learning
le = LabelEncoder()
df["label"] = le.fit_transform(df["label"])  # Encode "label" field

# Split data into subsets based on "label" for biased learning
train, test = train_test_split(df, test_size=0.3, random_state=42)
rare = train[train["label"] == 2]
outlier = train[train["label"] == 1]
safe = train[train["label"] == 3]
borderline = train[train["label"] == 0]

# Apply SMOTE to rare and outlier subsets for balancing
smote = SMOTE(random_state=42, sampling_strategy="auto", k_neighbors=1)
#rare_X, rare_y = smote.fit_resample(rare.drop(["outcome", "label"], axis=1), rare["outcome"])
outlier_X, outlier_y = smote.fit_resample(outlier.drop(["outcome", "label"], axis=1), outlier["outcome"])

# Apply NearMiss to safe and borderline subsets for balancing
ncr = NearMiss(version=1, sampling_strategy="majority", n_neighbors=2)
safe_X, safe_y = ncr.fit_resample(safe.drop(["outcome", "label"], axis=1), safe["outcome"])
borderline_X, borderline_y = ncr.fit_resample(borderline.drop(["outcome", "label"], axis=1), borderline["outcome"])

# Define models for each subset and model type
models = {
    "Naive Bayes": GaussianNB(),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "SVM": SVC(random_state=42, probability=True),
    "XGBoost": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
}

# Dictionary to hold precision-recall values for each model type
results = {}

# Train and evaluate models for each subset and model type
for model_name, model in models.items():
    model_safe = model
    model_safe.fit(safe_X, safe_y)

    model_borderline = model
    model_borderline.fit(borderline_X, borderline_y)

    model_rare = model
    model_rare.fit(rare_X, rare_y)

    model_outlier = model
    model_outlier.fit(outlier_X, outlier_y)

    # Ensemble for each model type
    ensemble = VotingClassifier(
        estimators=[
            ('safe', model_safe),
            ('borderline', model_borderline),
            #('rare', model_rare),
            ('outlier', model_outlier)
        ],
        voting='soft',
        weights=[1, 1, 2, 2]  # Adjust weights as needed
    )

    precisions, recalls = train_and_evaluate(ensemble, train.drop("outcome", axis=1), train["outcome"], test.drop("outcome", axis=1), test["outcome"], f"Biased Ensemble {model_name}")
    results[model_name] = (precisions, recalls)

# Plot Precision-Recall Curves as subplots
fig, axs = plt.subplots(2, 2, figsize=(12, 10))
axs = axs.ravel()  # Flattening to easily iterate over subplots

for i, (model_name, (precisions, recalls)) in enumerate(results.items()):
    axs[i].plot(recalls, precisions, label=f'Biased Ensemble {model_name}')
    axs[i].set_xlabel("Recall")
    axs[i].set_ylabel("Precision")
    axs[i].set_title(f"Precision-Recall Curve for {model_name}")
    axs[i].legend(loc="lower left")

plt.tight_layout()
plt.show()

#1
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score
from imblearn.over_sampling import SMOTE, ADASYN
from imblearn.under_sampling import RandomUnderSampler, NearMiss
from imblearn.combine import SMOTEENN
from imblearn.under_sampling import TomekLinks
from sklearn.ensemble import VotingClassifier
from sklearn.preprocessing import MinMaxScaler
from scipy.stats import iqr
import matplotlib.pyplot as plt
import numpy as np

#import data
from google.colab import drive
drive.mount('/content/drive')

# Code to read csv file into Colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'

import pandas as pd
downloaded = drive.CreateFile({'id':id})
downloaded.GetContentFile('cons Labelled Final')
df = pd.read_csv('cons Labelled Final')
# Dataset is now stored in a Pandas Dataframe

df  = df.drop("Unnamed: 0",axis=1)
df = df.drop("minority_count",axis=1)
df = df.drop("majority_count",axis=1)

# Split data into features and target
X = df.drop("label", axis=1)
y = df["label"]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Dynamic Threshold Selection
def calculate_thresholds(r):
    ts = np.percentile(r, 75) + 1.5 * iqr(r)
    tb = np.percentile(r, 50)
    tr = np.percentile(r, 25) - 1.5 * iqr(r)
    return ts, tb, tr

# Identify sample types dynamically
def identify_sample_types(X, y, k=5):
    from sklearn.neighbors import NearestNeighbors

    nn = NearestNeighbors(n_neighbors=k)
    nn.fit(X)
    neighbors = nn.kneighbors(X, return_distance=False)

    minority_counts = [sum(y[neighbors[i]] == 1) for i in range(len(X))]
    majority_counts = [k - count for count in minority_counts]

    r = [minority_counts[i] / (majority_counts[i] + 1) for i in range(len(X))]
    ts, tb, tr = calculate_thresholds(r)

    safe = [i for i in range(len(X)) if r[i] >= ts]
    borderline = [i for i in range(len(X)) if tb <= r[i] < ts]
    rare = [i for i in range(len(X)) if r[i] < tr]

    return safe, borderline, rare, ts, tb, tr

safe_idx, borderline_idx, rare_idx, ts, tb, tr = identify_sample_types(X_train.values, y_train.values)

# Experiment with different class imbalance approaches
def apply_resampling(X, y, method):
    if method == 'SMOTE':
        sampler = SMOTE(random_state=42)
    elif method == 'ADASYN':
        sampler = ADASYN(random_state=42)
    elif method == 'RUS':
        sampler = RandomUnderSampler(random_state=42)
    elif method == 'TomekLinks':
        sampler = TomekLinks()
    elif method == 'NearMiss':
        sampler = NearMiss(version=1)
    elif method == 'SMOTEENN':
        sampler = SMOTEENN(random_state=42)
    else:
        raise ValueError("Unknown resampling method")

    X_resampled, y_resampled = sampler.fit_resample(X, y)
    return X_resampled, y_resampled

# Customised Treatment of Sample Types
resampling_methods = ['SMOTE', 'ADASYN', 'RUS', 'TomekLinks', 'NearMiss', 'SMOTEENN']
def customised_resampling(X_train, y_train, safe_idx, borderline_idx, rare_idx):
    # Initialise empty lists for resampled data
    resampled_X = []
    resampled_y = []

    # Define a helper function to handle resampling with empty set checks
    def safe_resample(indices, method):
        if len(indices) == 0:
            return pd.DataFrame(), pd.Series(dtype=y_train.dtype)
        data = X_train.iloc[indices], y_train.iloc[indices]
        return apply_resampling(*data, method)

    # Resample each subset if it is not empty
    safe_resampled = safe_resample(safe_idx, method='RUS')
    borderline_resampled = safe_resample(borderline_idx, method='TomekLinks')
    rare_resampled = safe_resample(rare_idx, method='SMOTE')

    # Collect resampled data if not empty
    for resampled in [safe_resampled, borderline_resampled, rare_resampled]:
        if not resampled[0].empty:
            resampled_X.append(resampled[0])
            resampled_y.append(resampled[1])

    # Combine resampled data
    X_combined = pd.concat(resampled_X, axis=0)
    y_combined = pd.concat(resampled_y, axis=0)

    return X_combined, y_combined



X_resampled, y_resampled = customised_resampling(X_train, y_train, safe_idx, borderline_idx, rare_idx)

# Train classifiers for each sample type
safe_classifier = GaussianNB()
borderline_classifier = GaussianNB()
rare_classifier = GaussianNB()

safe_classifier.fit(X_train[safe_idx], y_train[safe_idx])
borderline_classifier.fit(X_train[borderline_idx], y_train[borderline_idx])
rare_classifier.fit(X_train[rare_idx], y_train[rare_idx])

# Ensemble construction
ensemble = VotingClassifier(
    estimators=[
        ('safe', safe_classifier),
        ('borderline', borderline_classifier),
        ('rare', rare_classifier)
    ],
    voting='soft',
    weights=[0.4, 0.3, 0.3]
)
ensemble.fit(X_resampled, y_resampled)

# Evaluate model
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]

    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    auroc = roc_auc_score(y_test, y_pred_proba)

    print(f"Precision: {precision}, Recall: {recall}, F1-score: {f1}, Accuracy: {accuracy}, AUROC: {auroc}")

    precisions, recalls, _ = precision_recall_curve(y_test, y_pred_proba)
    return precisions, recalls

precisions, recalls = evaluate_model(ensemble, X_test, y_test)

# Plot Precision-Recall Curve
plt.figure(figsize=(10, 8))
plt.plot(recalls, precisions, label='LEL Ensemble')
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve for LEL Ensemble")
plt.legend(loc="lower left")
plt.show()

#2
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler, TomekLinks
from sklearn.ensemble import VotingClassifier
from sklearn.preprocessing import MinMaxScaler
from sklearn.neighbors import NearestNeighbors
from scipy.stats import iqr
import matplotlib.pyplot as plt
import numpy as np

# Import data
from google.colab import drive
drive.mount('/content/drive')

# Load the dataset
link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

# Download the file
downloaded = drive.CreateFile({'id': id})
downloaded.GetContentFile('cons_Labelled_Final.csv')
df = pd.read_csv('cons_Labelled_Final.csv')

# Data preprocessing
df = df.drop(["Unnamed: 0", "minority_count", "majority_count"], axis=1)
X = df.drop("label", axis=1)
y = df["label"]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Dynamic threshold calculation
def calculate_thresholds(r):
    upper_quartile = np.percentile(r, 75)
    median = np.percentile(r, 50)
    lower_quartile = np.percentile(r, 25)
    iqr_value = iqr(r)

    ts = upper_quartile + 1.0 * iqr_value  # Safe threshold
    tb = median                            # Borderline threshold
    tr = lower_quartile - 1.0 * iqr_value  # Rare threshold
    return ts, tb, tr

# Identify sample types dynamically
def identify_sample_types(X, y, k=5):
    nn = NearestNeighbors(n_neighbors=k)
    nn.fit(X)
    neighbors = nn.kneighbors(X, return_distance=False)

    minority_counts = np.array([sum(y[neighbors[i]] == 1) for i in range(len(X))])
    majority_counts = k - minority_counts

    r = minority_counts / (majority_counts + 1e-5)  # Avoid division by zero
    ts, tb, tr = calculate_thresholds(r)

    safe = np.where(r >= ts)[0]
    borderline = np.where((tb <= r) & (r < ts))[0]
    rare = np.where(r < tr)[0]

    return safe, borderline, rare, ts, tb, tr

safe_idx, borderline_idx, rare_idx, ts, tb, tr = identify_sample_types(X_train.values, y_train.values)

# Resampling for each sample type
def apply_resampling(X, y, method):
    if method == 'SMOTE':
        sampler = SMOTE(random_state=42)
    elif method == 'RUS':
        sampler = RandomUnderSampler(random_state=42)
    elif method == 'TomekLinks':
        sampler = TomekLinks()
    else:
        raise ValueError("Unknown resampling method")

    X_resampled, y_resampled = sampler.fit_resample(X, y)
    return X_resampled, y_resampled

# Customised treatment of sample types
def customised_resampling(X_train, y_train, safe_idx, borderline_idx, rare_idx):
    def safe_resample(indices, method):
        if len(indices) == 0:
            return pd.DataFrame(), pd.Series(dtype=y_train.dtype)
        data = X_train.iloc[indices], y_train.iloc[indices]
        return apply_resampling(*data, method)

    safe_resampled = safe_resample(safe_idx, method='RUS')
    borderline_resampled = safe_resample(borderline_idx, method='TomekLinks')
    rare_resampled = safe_resample(rare_idx, method='SMOTE')

    resampled_X = []
    resampled_y = []

    for resampled in [safe_resampled, borderline_resampled, rare_resampled]:
        if not resampled[0].empty:
            resampled_X.append(resampled[0])
            resampled_y.append(resampled[1])

    X_combined = pd.concat(resampled_X, axis=0)
    y_combined = pd.concat(resampled_y, axis=0)

    return X_combined, y_combined

X_resampled, y_resampled = customised_resampling(X_train, y_train, safe_idx, borderline_idx, rare_idx)

# Train classifiers for each sample type
safe_classifier = GaussianNB()
borderline_classifier = GaussianNB()
rare_classifier = GaussianNB()

safe_classifier.fit(X_train.iloc[safe_idx], y_train.iloc[safe_idx])
borderline_classifier.fit(X_train.iloc[borderline_idx], y_train.iloc[borderline_idx])
rare_classifier.fit(X_train.iloc[rare_idx], y_train.iloc[rare_idx])

# Ensemble construction
ensemble = VotingClassifier(
    estimators=[
        ('safe', safe_classifier),
        ('borderline', borderline_classifier),
        ('rare', rare_classifier)
    ],
    voting='soft',
    weights=[0.4, 0.3, 0.3]
)
ensemble.fit(X_resampled, y_resampled)

# Evaluate model
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]

    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    auroc = roc_auc_score(y_test, y_pred_proba)

    print(f"Precision: {precision}, Recall: {recall}, F1-score: {f1}, Accuracy: {accuracy}, AUROC: {auroc}")

    precisions, recalls, _ = precision_recall_curve(y_test, y_pred_proba)
    return precisions, recalls

precisions, recalls = evaluate_model(ensemble, X_test, y_test)

# Plot Precision-Recall Curve
plt.figure(figsize=(10, 8))
plt.plot(recalls, precisions, label='LEL Ensemble')
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve for LEL Ensemble")
plt.legend(loc="lower left")
plt.show()

#dynamic thresholding
import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
from scipy.stats import iqr

# Dynamic threshold calculation
def calculate_thresholds(r):
    """
    Dynamically calculate thresholds for sample categorisation.
    """
    upper_quartile = np.percentile(r, 75)
    median = np.percentile(r, 50)
    lower_quartile = np.percentile(r, 25)
    iqr_value = iqr(r)

    ts = upper_quartile + 1.0 * iqr_value  # Safe threshold
    tb = median                           # Borderline threshold
    tr = lower_quartile - 1.0 * iqr_value  # Rare threshold
    return ts, tb, tr

# Identify sample types dynamically
def identify_sample_types(X, y, k=5):
    """
    Categorise samples dynamically into safe, borderline, and rare types.
    """
    nn = NearestNeighbors(n_neighbors=k)
    nn.fit(X)
    neighbors = nn.kneighbors(X, return_distance=False)

    minority_counts = np.array([sum(y[neighbors[i]] == 1) for i in range(len(X))])
    majority_counts = k - minority_counts

    r = minority_counts / (majority_counts + 1e-5)  # Avoid division by zero
    ts, tb, tr = calculate_thresholds(r)

    safe = np.where(r >= ts)[0]
    borderline = np.where((tb <= r) & (r < ts))[0]
    rare = np.where(r < tr)[0]

    return safe, borderline, rare, ts, tb, tr

# Example usage
# Assuming X_train and y_train are defined as your feature matrix and labels, respectively.
# X_train and y_train should be in numpy array format for this function.
safe_idx, borderline_idx, rare_idx, ts, tb, tr = identify_sample_types(X_train.values, y_train.values)

# Print out the number of samples in each category
print(f"Safe samples: {len(safe_idx)}")
print(f"Borderline samples: {len(borderline_idx)}")
print(f"Rare samples: {len(rare_idx)}")

# Print the thresholds
print(f"Thresholds - Safe (ts): {ts}, Borderline (tb): {tb}, Rare (tr): {tr}")

from google.colab import drive
    drive.mount('/content/drive')

    # Load the dataset
    link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
    id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'
    from pydrive.auth import GoogleAuth
    from pydrive.drive import GoogleDrive
    from google.colab import auth
    from oauth2client.client import GoogleCredentials

    auth.authenticate_user()
    gauth = GoogleAuth()
    gauth.credentials = GoogleCredentials.get_application_default()
    drive = GoogleDrive(gauth)

    # Download the file
    downloaded = drive.CreateFile({'id': id})
    downloaded.GetContentFile('cons_Labelled_Final.csv')
    df = pd.read_csv('cons_Labelled_Final.csv')

    # Data preprocessing
    df = df.drop(["Unnamed: 0", "minority_count", "majority_count"], axis=1)
    #X = df.drop("label", axis=1)
    X = df.drop(["label", "outcome"], axis=1)
    y = df["outcome"]

X

y

import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler
from scipy.stats import iqr

# Load the dataset
def load_data():
    # Assuming you have the dataset in CSV format
    # Import data
    from google.colab import drive
    drive.mount('/content/drive')

    # Load the dataset
    link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
    id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'
    from pydrive.auth import GoogleAuth
    from pydrive.drive import GoogleDrive
    from google.colab import auth
    from oauth2client.client import GoogleCredentials

    auth.authenticate_user()
    gauth = GoogleAuth()
    gauth.credentials = GoogleCredentials.get_application_default()
    drive = GoogleDrive(gauth)

    # Download the file
    downloaded = drive.CreateFile({'id': id})
    downloaded.GetContentFile('cons_Labelled_Final.csv')
    df = pd.read_csv('cons_Labelled_Final.csv')

    # Data preprocessing
    df = df.drop(["Unnamed: 0", "minority_count", "majority_count"], axis=1)
    #X = df.drop("label", axis=1)
    X = df.drop(["label", "outcome"], axis=1)
    y = df["outcome"]
    return X, y

# Dynamic threshold methods

# 1. IQR-Based Thresholding
def iqr_based_thresholding(r):
    upper_quartile = np.percentile(r, 75)
    median = np.percentile(r, 50)
    lower_quartile = np.percentile(r, 25)
    iqr_value = iqr(r)

    ts = upper_quartile + 1.0 * iqr_value
    tb = median
    tr = lower_quartile - 1.0 * iqr_value
    return ts, tb, tr

# 2. Percentile-Based Thresholding
def percentile_based_thresholding(r):
    ts = np.percentile(r, 90)
    tb = np.percentile(r, 50)
    tr = np.percentile(r, 10)
    return ts, tb, tr

# 3. Standard Deviation-Based Thresholding
def std_based_thresholding(r):
    mean = np.mean(r)
    std = np.std(r)
    ts = mean + 1.0 * std
    tb = mean
    tr = mean - 1.0 * std
    return ts, tb, tr

# 4. Cluster-Based Thresholding
def cluster_based_thresholding(r):
    r = r.reshape(-1, 1)
    if len(np.unique(r)) == 1:
        return 0.0, 0.0, 0.0

    kmeans = KMeans(n_clusters=3, random_state=42).fit(r)
    cluster_centers = sorted(kmeans.cluster_centers_.flatten())
    ts, tb, tr = cluster_centers[2], cluster_centers[1], cluster_centers[0]
    return ts, tb, tr

# 5. Dynamic Quantile Binning
def quantile_binning_thresholding(r):
    ts = np.percentile(r, 75)
    tb = np.percentile(r, 50)
    tr = np.percentile(r, 25)
    return ts, tb, tr

# 6. Adaptive Thresholding with Local Density
def density_based_thresholding(X, y, k=5):
    nn = NearestNeighbors(n_neighbors=k).fit(X)
    neighbors = nn.kneighbors(X, return_distance=False)
    minority_counts = np.array([sum(y[neighbors[i]] == 1) for i in range(len(X))])
    majority_counts = k - minority_counts
    r = minority_counts / (majority_counts + 1e-5)
    ts, tb, tr = iqr_based_thresholding(r)
    return ts, tb, tr

# 7. Distance-Based Thresholding
def distance_based_thresholding(X):
    nn = NearestNeighbors(n_neighbors=5).fit(X)
    distances, _ = nn.kneighbors(X)
    avg_distance = np.mean(distances, axis=1)
    ts, tb, tr = iqr_based_thresholding(avg_distance)
    return ts, tb, tr

# 8. Dynamic Range Scaling
def range_scaling_thresholding(r):
    scaler = MinMaxScaler()
    r_scaled = scaler.fit_transform(r.reshape(-1, 1)).flatten()
    ts = 0.8
    tb = 0.5
    tr = 0.2
    return ts, tb, tr

# Function to apply a thresholding method and categorise samples
def apply_thresholding(X, y, thresholding_func):
    nn = NearestNeighbors(n_neighbors=5).fit(X)
    neighbors = nn.kneighbors(X, return_distance=False)

    minority_counts = np.array([sum(y[neighbors[i]] == 1) for i in range(len(X))])
    majority_counts = 5 - minority_counts

    r = minority_counts / (majority_counts + 1e-5)
    ts, tb, tr = thresholding_func(r)

    safe = np.where(r >= ts)[0]
    borderline = np.where((tb <= r) & (r < ts))[0]
    rare = np.where(r < tr)[0]

    return len(safe), len(borderline), len(rare), ts, tb, tr

# Main script to load data and evaluate methods
X, y = load_data()
methods = [
    ("IQR-Based", iqr_based_thresholding),
    ("Percentile-Based", percentile_based_thresholding),
    ("Standard Deviation-Based", std_based_thresholding),
    ("Cluster-Based", cluster_based_thresholding),
    ("Quantile Binning", quantile_binning_thresholding),
    ("Density-Based", lambda r: density_based_thresholding(X.values, y.values)),
    ("Distance-Based", lambda r: distance_based_thresholding(X.values)),
    ("Range Scaling", range_scaling_thresholding)
]

for name, method in methods:
    try:
        safe_count, borderline_count, rare_count, ts, tb, tr = apply_thresholding(X.values, y.values, method)
        print(f"{name}:")
        print(f"  Safe samples: {safe_count}")
        print(f"  Borderline samples: {borderline_count}")
        print(f"  Rare samples: {rare_count}")
        print(f"  Thresholds - Safe (ts): {ts}, Borderline (tb): {tb}, Rare (tr): {tr}\n")
    except Exception as e:
        print(f"{name} failed with error: {e}\n")

X

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import NearestNeighbors
from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score
from sklearn.ensemble import VotingClassifier
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler, TomekLinks
from scipy.stats import iqr

# Load the dataset
def load_data():
    from google.colab import drive
    drive.mount('/content/drive')

    # Load the dataset
    link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
    id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'
    from pydrive.auth import GoogleAuth
    from pydrive.drive import GoogleDrive
    from google.colab import auth
    from oauth2client.client import GoogleCredentials

    auth.authenticate_user()
    gauth = GoogleAuth()
    gauth.credentials = GoogleCredentials.get_application_default()
    drive = GoogleDrive(gauth)

    # Download the file
    downloaded = drive.CreateFile({'id': id})
    downloaded.GetContentFile('cons_Labelled_Final.csv')
    df = pd.read_csv('cons_Labelled_Final.csv')

    # Data preprocessing
    df = df.drop(["Unnamed: 0", "minority_count", "majority_count"], axis=1)
    X = df.drop(["label", "outcome"], axis=1)
    y = df["outcome"]
    return X, y

# Preprocess the dataset
def preprocess_data(X):
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    return X_scaled

# Calculate local neighbourhood ratios
def calculate_ratios(X, y, k=5):
    nn = NearestNeighbors(n_neighbors=k).fit(X)
    neighbors = nn.kneighbors(X, return_distance=False)

    minority_counts = np.array([sum(y.iloc[neighbors[i]] == 1) for i in range(len(X))])
    majority_counts = k - minority_counts

    r = minority_counts / (majority_counts + 1e-5)  # Avoid division by zero
    return r

# Dynamic thresholding methods
def iqr_based_thresholding(r):
    upper_quartile = np.percentile(r, 75)
    median = np.percentile(r, 50)
    lower_quartile = np.percentile(r, 25)
    iqr_value = iqr(r)

    ts = upper_quartile + 1.0 * iqr_value
    tb = median
    tr = lower_quartile - 1.0 * iqr_value
    return ts, tb, tr

def percentile_based_thresholding(r):
    ts = np.percentile(r, 90)
    tb = np.percentile(r, 50)
    tr = np.percentile(r, 10)
    return ts, tb, tr

def std_based_thresholding(r):
    mean = np.mean(r)
    std = np.std(r)
    ts = mean + 1.0 * std
    tb = mean
    tr = mean - 1.0 * std
    return ts, tb, tr

def cluster_based_thresholding(r):
    r = r.reshape(-1, 1)
    if len(np.unique(r)) == 1:
        return 0.0, 0.0, 0.0

    kmeans = KMeans(n_clusters=3, random_state=42).fit(r)
    cluster_centers = sorted(kmeans.cluster_centers_.flatten())
    ts, tb, tr = cluster_centers[2], cluster_centers[1], cluster_centers[0]
    return ts, tb, tr

def density_based_thresholding(X, y, k=5):
    nn = NearestNeighbors(n_neighbors=k).fit(X)
    neighbors = nn.kneighbors(X, return_distance=False)
    minority_counts = np.array([sum(y.iloc[neighbors[i]] == 1) for i in range(len(X))])
    majority_counts = k - minority_counts
    r = minority_counts / (majority_counts + 1e-5)
    ts, tb, tr = iqr_based_thresholding(r)
    return ts, tb, tr

def distance_based_thresholding(X):
    nn = NearestNeighbors(n_neighbors=5).fit(X)
    distances, _ = nn.kneighbors(X)
    avg_distance = np.mean(distances, axis=1)
    ts, tb, tr = iqr_based_thresholding(avg_distance)
    return ts, tb, tr

def range_scaling_thresholding(r):
    scaler = MinMaxScaler()
    r_scaled = scaler.fit_transform(r.reshape(-1, 1)).flatten()
    ts = 0.8
    tb = 0.5
    tr = 0.2
    return ts, tb, tr

# Categorise samples based on thresholds
def categorise_samples(r, ts, tb, tr):
    safe = np.where(r >= ts)[0]
    borderline = np.where((tb <= r) & (r < ts))[0]
    rare = np.where(r < tr)[0]
    return safe, borderline, rare

# Customised resampling
def customised_resampling(X, y, safe_idx, borderline_idx, rare_idx):
    def safe_resample(indices, method):
        if len(indices) == 0:
            return pd.DataFrame(), pd.Series(dtype=y.dtype)
        data = X.iloc[indices], y.iloc[indices]
        sampler = SMOTE(random_state=42) if method == 'SMOTE' else RandomUnderSampler(random_state=42)
        return sampler.fit_resample(*data)

    safe_resampled = safe_resample(safe_idx, method='RUS')
    borderline_resampled = safe_resample(borderline_idx, method='TomekLinks')
    rare_resampled = safe_resample(rare_idx, method='SMOTE')

    resampled_X = []
    resampled_y = []

    for resampled in [safe_resampled, borderline_resampled, rare_resampled]:
        if not resampled[0].empty:
            resampled_X.append(resampled[0])
            resampled_y.append(resampled[1])

    X_combined = pd.concat(resampled_X, axis=0)
    y_combined = pd.concat(resampled_y, axis=0)

    return X_combined, y_combined

# Evaluate model
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]

    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    auroc = roc_auc_score(y_test, y_pred_proba)

    print(f"Precision: {precision}, Recall: {recall}, F1-score: {f1}, Accuracy: {accuracy}, AUROC: {auroc}")

    precisions, recalls, _ = precision_recall_curve(y_test, y_pred_proba)
    plt.plot(recalls, precisions, label='Precision-Recall Curve')
    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.legend()
    plt.show()

# Main script
X, y = load_data()
X_scaled = preprocess_data(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

methods = [
    ("IQR-Based", iqr_based_thresholding),
    ("Percentile-Based", percentile_based_thresholding),
    ("Standard Deviation-Based", std_based_thresholding),
    ("Cluster-Based", cluster_based_thresholding),
    ("Density-Based", lambda r: density_based_thresholding(pd.DataFrame(X_train), pd.Series(y_train))),
    ("Distance-Based", lambda r: distance_based_thresholding(pd.DataFrame(X_train))),
    ("Range Scaling", range_scaling_thresholding)
]

for name, method in methods:
    try:
        r = calculate_ratios(pd.DataFrame(X_train), pd.Series(y_train))
        ts, tb, tr = method(r)
        safe_idx, borderline_idx, rare_idx = categorise_samples(r, ts, tb, tr)

        X_resampled, y_resampled = customised_resampling(pd.DataFrame(X_train), pd.Series(y_train), safe_idx, borderline_idx, rare_idx)

        # Train classifiers
        safe_classifier = GaussianNB()
        borderline_classifier = GaussianNB()
        rare_classifier = GaussianNB()

        safe_classifier.fit(X_resampled.iloc[safe_idx], y_resampled.iloc[safe_idx])
        borderline_classifier.fit(X_resampled.iloc[borderline_idx], y_resampled.iloc[borderline_idx])
        rare_classifier.fit(X_resampled.iloc[rare_idx], y_resampled.iloc[rare_idx])

        # Ensemble construction
        ensemble = VotingClassifier(
            estimators=[
                ('safe', safe_classifier),
                ('borderline', borderline_classifier),
                ('rare', rare_classifier)
            ],
            voting='soft',
            weights=[0.4, 0.3, 0.3]
        )
        ensemble.fit(X_resampled, y_resampled)

        print(f"Results for {name}:")
        evaluate_model(ensemble, X_test, y_test)
    except Exception as e:
        print(f"{name} failed with error: {e}\n")

import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.covariance import EllipticEnvelope
from scipy.spatial import distance
from scipy.stats import iqr, zscore
import networkx as nx
from sklearn.mixture import GaussianMixture

# Load the dataset
def load_data():
    from google.colab import drive
    drive.mount('/content/drive')

    # Load the dataset
    link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
    id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'
    from pydrive.auth import GoogleAuth
    from pydrive.drive import GoogleDrive
    from google.colab import auth
    from oauth2client.client import GoogleCredentials

    auth.authenticate_user()
    gauth = GoogleAuth()
    gauth.credentials = GoogleCredentials.get_application_default()
    drive = GoogleDrive(gauth)

    # Download the file
    downloaded = drive.CreateFile({'id': id})
    downloaded.GetContentFile('cons_Labelled_Final.csv')
    df = pd.read_csv('cons_Labelled_Final.csv')

    # Data preprocessing
    df = df.drop(["Unnamed: 0", "minority_count", "majority_count"], axis=1)
    X = df.drop(["label", "outcome"], axis=1)
    y = df["outcome"]
    return X, y

# Preprocess the dataset
def preprocess_data(X):
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    return X_scaled

# Approach 1: Density-Based Clustering (DBSCAN)
def density_based_clustering(X):
    dbscan = DBSCAN(eps=0.5, min_samples=5).fit(X)
    labels = dbscan.labels_
    safe = np.sum(labels != -1)
    rare = np.sum(labels == -1)
    return safe, 0, rare  # DBSCAN does not directly define borderline samples

# Approach 2: Local Outlier Factor (LOF)
def local_outlier_factor(X):
    lof = NearestNeighbors(n_neighbors=5).fit(X)
    distances, _ = lof.kneighbors(X)
    avg_distances = np.mean(distances, axis=1)
    ts = np.percentile(avg_distances, 75) + 1.5 * iqr(avg_distances)
    tr = np.percentile(avg_distances, 25) - 1.5 * iqr(avg_distances)

    safe = np.sum(avg_distances < ts)
    rare = np.sum(avg_distances > ts)
    borderline = np.sum((avg_distances >= tr) & (avg_distances <= ts))
    return safe, borderline, rare

# Approach 3: K-Means Clustering
def kmeans_clustering(X):
    kmeans = KMeans(n_clusters=3, random_state=42).fit(X)
    cluster_centers = sorted(kmeans.cluster_centers_, key=lambda c: np.linalg.norm(c))

    distances = np.linalg.norm(X - kmeans.cluster_centers_[kmeans.labels_], axis=1)
    ts = np.percentile(distances, 75)
    tr = np.percentile(distances, 25)

    safe = np.sum(distances <= tr)
    rare = np.sum(distances > ts)
    borderline = np.sum((distances > tr) & (distances <= ts))
    return safe, borderline, rare

# Approach 4: Mahalanobis Distance
def mahalanobis_distance(X):
    cov = np.cov(X, rowvar=False)
    cov_inv = np.linalg.inv(cov)
    mean = np.mean(X, axis=0)
    mahal_distances = np.array([distance.mahalanobis(x, mean, cov_inv) for x in X])

    ts = np.percentile(mahal_distances, 75)
    tr = np.percentile(mahal_distances, 25)

    safe = np.sum(mahal_distances <= tr)
    rare = np.sum(mahal_distances > ts)
    borderline = np.sum((mahal_distances > tr) & (mahal_distances <= ts))
    return safe, borderline, rare

# Approach 5: Gaussian Mixture Models (GMM)
def gaussian_mixture_model(X):
    gmm = GaussianMixture(n_components=3, random_state=42).fit(X)
    labels = gmm.predict(X)
    probabilities = gmm.predict_proba(X)

    rare = np.sum(np.max(probabilities, axis=1) < 0.5)
    safe = np.sum(np.max(probabilities, axis=1) >= 0.8)
    borderline = len(X) - safe - rare
    return safe, borderline, rare

# Approach 6: Graph-Based (Degree Centrality)
def graph_based_centrality(X):
    knn_graph = NearestNeighbors(n_neighbors=5).fit(X)
    neighbors = knn_graph.kneighbors_graph(X).toarray()
    graph = nx.from_numpy_matrix(neighbors)

    centrality = nx.degree_centrality(graph)
    centrality_values = np.array(list(centrality.values()))

    ts = np.percentile(centrality_values, 75)
    tr = np.percentile(centrality_values, 25)

    safe = np.sum(centrality_values >= ts)
    rare = np.sum(centrality_values <= tr)
    borderline = len(X) - safe - rare
    return safe, borderline, rare

# Approach 7: Statistical Z-Score
def zscore_analysis(X):
    z_scores = zscore(X, axis=0)
    avg_z_scores = np.mean(np.abs(z_scores), axis=1)

    ts = 2  # Z-score threshold for "safe"
    tr = 0.5  # Z-score threshold for "rare"

    safe = np.sum(avg_z_scores < tr)
    rare = np.sum(avg_z_scores > ts)
    borderline = len(X) - safe - rare
    return safe, borderline, rare

# Main script
X, y = load_data()
X_scaled = preprocess_data(X)

methods = [
    ("Density-Based Clustering (DBSCAN)", density_based_clustering),
    ("Local Outlier Factor (LOF)", local_outlier_factor),
    ("K-Means Clustering", kmeans_clustering),
    ("Mahalanobis Distance", mahalanobis_distance),
    ("Gaussian Mixture Model (GMM)", gaussian_mixture_model),
    ("Graph-Based Centrality", graph_based_centrality),
    ("Statistical Z-Score", zscore_analysis)
]

for name, method in methods:
    try:
        safe, borderline, rare = method(X_scaled)
        print(f"{name}:")
        print(f"  Safe samples: {safe}")
        print(f"  Borderline samples: {borderline}")
        print(f"  Rare samples: {rare}\n")
    except Exception as e:
        print(f"{name} failed with error: {e}\n")

import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.mixture import GaussianMixture
from scipy.spatial import distance
from scipy.stats import zscore
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import VotingClassifier
from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score
from sklearn.model_selection import train_test_split

# Load the dataset
def load_data():
    from google.colab import drive
    drive.mount('/content/drive')

    # Load the dataset
    link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
    id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'
    from pydrive.auth import GoogleAuth
    from pydrive.drive import GoogleDrive
    from google.colab import auth
    from oauth2client.client import GoogleCredentials

    auth.authenticate_user()
    gauth = GoogleAuth()
    gauth.credentials = GoogleCredentials.get_application_default()
    drive = GoogleDrive(gauth)

    # Download the file
    downloaded = drive.CreateFile({'id': id})
    downloaded.GetContentFile('cons_Labelled_Final.csv')
    df = pd.read_csv('cons_Labelled_Final.csv')

    # Data preprocessing
    df = df.drop(["Unnamed: 0", "minority_count", "majority_count"], axis=1)
    X = df.drop(["label", "outcome"], axis=1)
    y = df["outcome"]
    return X, y

# Preprocess the dataset
def preprocess_data(X):
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    return X_scaled

# Approach 1: Mahalanobis Distance
def mahalanobis_distance(X):
    cov = np.cov(X, rowvar=False)
    cov_inv = np.linalg.inv(cov)
    mean = np.mean(X, axis=0)
    mahal_distances = np.array([distance.mahalanobis(x, mean, cov_inv) for x in X])

    ts = np.percentile(mahal_distances, 75)
    tr = np.percentile(mahal_distances, 25)

    safe = np.where(mahal_distances <= tr)[0]
    rare = np.where(mahal_distances > ts)[0]
    borderline = np.where((mahal_distances > tr) & (mahal_distances <= ts))[0]
    return safe, borderline, rare

# Approach 2: Gaussian Mixture Models (GMM)
def gaussian_mixture_model(X):
    gmm = GaussianMixture(n_components=3, random_state=42).fit(X)
    probabilities = gmm.predict_proba(X)

    rare = np.where(np.max(probabilities, axis=1) < 0.5)[0]
    safe = np.where(np.max(probabilities, axis=1) >= 0.8)[0]
    borderline = np.setdiff1d(np.arange(len(X)), np.union1d(safe, rare))
    return safe, borderline, rare

# Approach 3: Statistical Z-Score
def zscore_analysis(X):
    z_scores = zscore(X, axis=0)
    avg_z_scores = np.mean(np.abs(z_scores), axis=1)

    ts = 2  # Z-score threshold for "safe"
    tr = 0.5  # Z-score threshold for "rare"

    safe = np.where(avg_z_scores < tr)[0]
    rare = np.where(avg_z_scores > ts)[0]
    borderline = np.setdiff1d(np.arange(len(X)), np.union1d(safe, rare))
    return safe, borderline, rare

# Customised resampling
def customised_resampling(X, y, safe_idx, borderline_idx, rare_idx):
    safe_X, safe_y = X[safe_idx], y[safe_idx]
    borderline_X, borderline_y = X[borderline_idx], y[borderline_idx]
    rare_X, rare_y = X[rare_idx], y[rare_idx]

    X_combined = np.concatenate([safe_X, borderline_X, rare_X], axis=0)
    y_combined = np.concatenate([safe_y, borderline_y, rare_y], axis=0)

    return X_combined, y_combined

# Evaluate model
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]

    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    auroc = roc_auc_score(y_test, y_pred_proba)

    print(f"Precision: {precision}, Recall: {recall}, F1-score: {f1}, Accuracy: {accuracy}, AUROC: {auroc}")

    precisions, recalls, _ = precision_recall_curve(y_test, y_pred_proba)
    return precisions, recalls

# Main script
X, y = load_data()
X_scaled = preprocess_data(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

methods = [
    ("Mahalanobis Distance", mahalanobis_distance),
    ("Gaussian Mixture Model (GMM)", gaussian_mixture_model),
    ("Statistical Z-Score", zscore_analysis)
]

for name, method in methods:
    try:
        safe_idx, borderline_idx, rare_idx = method(X_train)
        X_resampled, y_resampled = customised_resampling(X_train, y_train.to_numpy(), safe_idx, borderline_idx, rare_idx)

        # Train classifiers
        safe_classifier = GaussianNB()
        borderline_classifier = GaussianNB()
        rare_classifier = GaussianNB()

        safe_classifier.fit(X_train[safe_idx], y_train.iloc[safe_idx])
        borderline_classifier.fit(X_train[borderline_idx], y_train.iloc[borderline_idx])
        rare_classifier.fit(X_train[rare_idx], y_train.iloc[rare_idx])

        # Ensemble construction
        ensemble = VotingClassifier(
            estimators=[
                ('safe', safe_classifier),
                ('borderline', borderline_classifier),
                ('rare', rare_classifier)
            ],
            voting='soft',
            weights=[0.4, 0.3, 0.3]
        )
        ensemble.fit(X_resampled, y_resampled)

        print(f"Results for {name}:")
        precisions, recalls = evaluate_model(ensemble, X_test, y_test)

        # Plot Precision-Recall Curve
        import matplotlib.pyplot as plt
        plt.figure(figsize=(10, 8))
        plt.plot(recalls, precisions, label=name)
        plt.xlabel("Recall")
        plt.ylabel("Precision")
        plt.title(f"Precision-Recall Curve for {name}")
        plt.legend()
        plt.show()

    except Exception as e:
        print(f"{name} failed with error: {e}\n")

import pandas as pd
import numpy as np
from sklearn.neighbors import NearestNeighbors
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.mixture import GaussianMixture
from scipy.spatial import distance
from scipy.stats import zscore
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import VotingClassifier
from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score
from sklearn.model_selection import train_test_split

# Load the dataset
def load_data():
    from google.colab import drive
    drive.mount('/content/drive')

    # Load the dataset
    link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
    id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'
    from pydrive.auth import GoogleAuth
    from pydrive.drive import GoogleDrive
    from google.colab import auth
    from oauth2client.client import GoogleCredentials

    auth.authenticate_user()
    gauth = GoogleAuth()
    gauth.credentials = GoogleCredentials.get_application_default()
    drive = GoogleDrive(gauth)

    # Download the file
    downloaded = drive.CreateFile({'id': id})
    downloaded.GetContentFile('cons_Labelled_Final.csv')
    df = pd.read_csv('cons_Labelled_Final.csv')

    # Data preprocessing
    df = df.drop(["Unnamed: 0", "minority_count", "majority_count"], axis=1)
    X = df.drop(["label", "outcome"], axis=1)
    y = df["outcome"]
    return X, y

# Preprocess the dataset
def preprocess_data(X):
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    return X_scaled

# Approach 1: Mahalanobis Distance
def mahalanobis_distance(X):
    cov = np.cov(X, rowvar=False)
    cov_inv = np.linalg.inv(cov)
    mean = np.mean(X, axis=0)
    mahal_distances = np.array([distance.mahalanobis(x, mean, cov_inv) for x in X])

    ts = np.percentile(mahal_distances, 75)
    tr = np.percentile(mahal_distances, 25)

    safe = np.where(mahal_distances <= tr)[0]
    rare = np.where(mahal_distances > ts)[0]
    borderline = np.where((mahal_distances > tr) & (mahal_distances <= ts))[0]
    return safe, borderline, rare

# Approach 2: Gaussian Mixture Models (GMM)
def gaussian_mixture_model(X):
    gmm = GaussianMixture(n_components=3, random_state=42).fit(X)
    probabilities = gmm.predict_proba(X)

    rare = np.where(np.max(probabilities, axis=1) < 0.5)[0]
    safe = np.where(np.max(probabilities, axis=1) >= 0.8)[0]
    borderline = np.setdiff1d(np.arange(len(X)), np.union1d(safe, rare))
    return safe, borderline, rare

# Approach 3: Statistical Z-Score (Dynamic Thresholds)
def zscore_analysis(X):
    z_scores = zscore(X, axis=0)
    avg_z_scores = np.mean(np.abs(z_scores), axis=1)

    # Determine dynamic thresholds
    ts = np.percentile(avg_z_scores, 75) + 1.5 * np.std(avg_z_scores)
    tr = np.percentile(avg_z_scores, 25) - 1.5 * np.std(avg_z_scores)

    safe = np.where(avg_z_scores < tr)[0]
    rare = np.where(avg_z_scores > ts)[0]
    borderline = np.setdiff1d(np.arange(len(X)), np.union1d(safe, rare))
    return safe, borderline, rare

# Customised resampling
def customised_resampling(X, y, safe_idx, borderline_idx, rare_idx):
    safe_X, safe_y = X[safe_idx], y[safe_idx]
    borderline_X, borderline_y = X[borderline_idx], y[borderline_idx]
    rare_X, rare_y = X[rare_idx], y[rare_idx]

    X_combined = np.concatenate([safe_X, borderline_X, rare_X], axis=0)
    y_combined = np.concatenate([safe_y, borderline_y, rare_y], axis=0)

    return X_combined, y_combined

# Evaluate model
def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1]

    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    auroc = roc_auc_score(y_test, y_pred_proba)

    print(f"Precision: {precision}, Recall: {recall}, F1-score: {f1}, Accuracy: {accuracy}, AUROC: {auroc}")

    precisions, recalls, _ = precision_recall_curve(y_test, y_pred_proba)
    return precisions, recalls

# Main script
X, y = load_data()
X_scaled = preprocess_data(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

methods = [
    ("Mahalanobis Distance", mahalanobis_distance),
    ("Gaussian Mixture Model (GMM)", gaussian_mixture_model),
    ("Statistical Z-Score", zscore_analysis)
]

for name, method in methods:
    try:
        safe_idx, borderline_idx, rare_idx = method(X_train)
        X_resampled, y_resampled = customised_resampling(X_train, y_train.to_numpy(), safe_idx, borderline_idx, rare_idx)

        # Train classifiers
        safe_classifier = GaussianNB()
        borderline_classifier = GaussianNB()
        rare_classifier = GaussianNB()

        safe_classifier.fit(X_train[safe_idx], y_train.iloc[safe_idx])
        borderline_classifier.fit(X_train[borderline_idx], y_train.iloc[borderline_idx])
        rare_classifier.fit(X_train[rare_idx], y_train.iloc[rare_idx])

        # Ensemble construction
        ensemble = VotingClassifier(
            estimators=[
                ('safe', safe_classifier),
                ('borderline', borderline_classifier),
                ('rare', rare_classifier)
            ],
            voting='soft',
            weights=[0.4, 0.3, 0.3]
        )
        ensemble.fit(X_resampled, y_resampled)

        print(f"Results for {name}:")
        precisions, recalls = evaluate_model(ensemble, X_test, y_test)

        # Plot Precision-Recall Curve
        import matplotlib.pyplot as plt
        plt.figure(figsize=(10, 8))
        plt.plot(recalls, precisions, label=name)
        plt.xlabel("Recall")
        plt.ylabel("Precision")
        plt.title(f"Precision-Recall Curve for {name}")
        plt.legend()
        plt.show()

    except Exception as e:
        print(f"{name} failed with error: {e}\n")

import pandas as pd
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import NearMiss
from sklearn.preprocessing import LabelEncoder
from scipy.spatial import distance
from scipy.optimize import minimize
import numpy as np
from google.colab import drive

# Import data
drive.mount('/content/drive')

# Read CSV file into Colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# Authenticate and create the PyDrive client
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/file/d/1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ/view?usp=drive_link'
id = '1Cwg4mtQScTimnMkauJmEtwX0nal8o5lZ'

downloaded = drive.CreateFile({'id': id})
downloaded.GetContentFile('cons Labelled Final')
df = pd.read_csv('cons Labelled Final')

# Drop unnecessary columns
df = df.drop(["Unnamed: 0", "minority_count", "majority_count"], axis=1)

# Separate features and labels
X = df.drop(["outcome", "label"], axis=1)
y = df["outcome"]

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Function to calculate Mahalanobis Distance and classify sample types dynamically
def mahalanobis_distance_dynamic(X):
    cov = np.cov(X, rowvar=False)
    cov_inv = np.linalg.inv(cov)
    mean = np.mean(X, axis=0)
    mahal_distances = np.array([distance.mahalanobis(x, mean, cov_inv) for x in X])

    def optimize_thresholds(thresholds):
        ts, tr = thresholds
        if ts <= tr or ts < 0 or tr < 0:
            return np.inf  # Invalid thresholds

        safe_count = np.sum(mahal_distances <= tr)
        borderline_count = np.sum((mahal_distances > tr) & (mahal_distances <= ts))
        rare_count = np.sum(mahal_distances > ts)

        # Objective: Balance the sizes of the three groups
        return np.abs(safe_count - borderline_count) + np.abs(borderline_count - rare_count)

    # Initial guesses for ts and tr (percentile-based)
    initial_thresholds = [np.percentile(mahal_distances, 75), np.percentile(mahal_distances, 25)]

    # Optimize thresholds
    result = minimize(optimize_thresholds, initial_thresholds, method='Nelder-Mead')

    ts, tr = result.x
    safe = np.where(mahal_distances <= tr)[0]
    rare = np.where(mahal_distances > ts)[0]
    borderline = np.where((mahal_distances > tr) & (mahal_distances <= ts))[0]

    return safe, borderline, rare

# Function to train and evaluate a model, and return probabilities for precision-recall curve
def train_and_evaluate(model, X_train, y_train, X_test, y_test, label):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None

    # Print evaluation metrics
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    accuracy = accuracy_score(y_test, y_pred)
    auroc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else "N/A"

    print(f"{label} - Precision: {precision}, Recall: {recall}, F1-score: {f1}, Accuracy: {accuracy}, AUROC: {auroc}")

    # Precision-recall curve if probabilities are available
    if y_pred_proba is not None:
        precisions, recalls, _ = precision_recall_curve(y_test, y_pred_proba)
        return precisions, recalls
    return None, None

# Custom ensemble function
def custom_ensemble_predict_proba(models, X):
    probas = [model.predict_proba(X)[:, 1] for model in models]
    return np.mean(probas, axis=0)

# ABEL Ensemble XGBoost - Using Dynamic Mahalanobis Distance for Sample Type Classification
le = LabelEncoder()
df["label"] = le.fit_transform(df["label"])  # Encode "label" field if not already encoded

# Split dataset into train and test specifically for ABEL ensemble
train, test = train_test_split(df, test_size=0.3, random_state=42)

# Calculate Mahalanobis distance and classify sample types dynamically
train_X = train.drop(["outcome"], axis=1).values
safe_idx, borderline_idx, rare_idx = mahalanobis_distance_dynamic(train_X)

# Subset data based on sample types
safe = train.iloc[safe_idx]
borderline = train.iloc[borderline_idx]
rare = train.iloc[rare_idx]

# Apply SMOTE to rare subset
smote = SMOTE(random_state=42)
rare_X, rare_y = smote.fit_resample(rare.drop(["outcome"], axis=1), rare["outcome"])

# Apply NearMiss to safe and borderline subsets
ncr = NearMiss(version=1, sampling_strategy="majority", n_neighbors=2)
safe_X, safe_y = ncr.fit_resample(safe.drop(["outcome"], axis=1), safe["outcome"])
borderline_X, borderline_y = ncr.fit_resample(borderline.drop(["outcome"], axis=1), borderline["outcome"])

# Train XGBoost models for ABEL ensemble
xgb_safe = XGBClassifier(random_state=42, eval_metric='logloss')
xgb_safe.fit(safe_X, safe_y)
xgb_borderline = XGBClassifier(random_state=42, eval_metric='logloss')
xgb_borderline.fit(borderline_X, borderline_y)

# Custom ensemble predictions
ensemble_proba = custom_ensemble_predict_proba([xgb_safe, xgb_borderline], test.drop("outcome", axis=1))
ensemble_pred = (ensemble_proba >= 0.5).astype(int)

# Evaluate custom ensemble
precision = precision_score(test["outcome"], ensemble_pred)
recall = recall_score(test["outcome"], ensemble_pred)
f1 = f1_score(test["outcome"], ensemble_pred)
accuracy = accuracy_score(test["outcome"], ensemble_pred)
auroc = roc_auc_score(test["outcome"], ensemble_proba)

print(f"ABEL Ensemble XGBoost - Precision: {precision}, Recall: {recall}, F1-score: {f1}, Accuracy: {accuracy}, AUROC: {auroc}")

# Plot Precision-Recall Curve
precisions, recalls, _ = precision_recall_curve(test["outcome"], ensemble_proba)
plt.figure(figsize=(10, 8))
plt.plot(recalls, precisions, label='ABEL Ensemble XGBoost')
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve")
plt.legend(loc="lower left")
plt.show()